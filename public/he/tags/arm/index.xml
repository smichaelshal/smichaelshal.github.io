<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arm on Michael Shalitin</title>
    <link>https://smichaelshal.github.io/he/tags/arm/</link>
    <description>Recent content in Arm on Michael Shalitin</description>
    <generator>Hugo</generator>
    <language>he</language>
    <lastBuildDate>Sat, 21 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://smichaelshal.github.io/he/tags/arm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Causal &amp; Physics</title>
      <link>https://smichaelshal.github.io/he/posts/causal--physics/</link>
      <pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/causal--physics/</guid>
      <description>&lt;h2 id=&#34;ראייה-מורכבת-יותר-של-זיכרון&#34;&gt;ראייה מורכבת יותר של זיכרון&lt;/h2&gt;&#xA;&lt;p&gt;מערכות מחשוב מודרניות מספקות אופטימיזציות וביצועים גבוהים אבל זה לא מגיע בחינם, כל אלה גורמים לסיבוך משמעותי, ולכן הרבה פעמים משתמשים בכלים שגורמים לכל הסיבוך הזה להיות שקוף כלפי המשתמש כמו שפות high level,  מנגנוני נעילה וכל מיני מנגנונים אחרים.&lt;/p&gt;&#xA;&lt;p&gt;בצורה הזאת אפשר לדמות שפות high level ומנגנוני נעילה למערכת שמתפקדת על פי עקרונות של פיזיקה ניוטונית: כשיש נעילה, המערכת מתנהגת בצורה דטרמיניסטית וצפויה, וניתן לדעת בוודאות מה יתרחש בכל מצב נתון. לעומת זאת, במעבר לרמות נמוכות יותר של ניהול זיכרון (למשל, ניהול זיכרון במערכות מרובות ליבות ללא נעילה), המצב מתחיל להזכיר את עקרונות הפיזיקה הקוונטית, שבהם אירועים מפתיעים יכולים להתרחש, וההבנה המלאה של התהליכים מורכבת יותר. רק מעטים יטענו שהם מבינים את כל ההתרחשויות בעולם הזה. אמנם לרוב ניתן לפעול היטב בסביבה זו מבלי להבין את הפרטים המורכבים, אך ישנם מקרים שבהם ידע מעמיק בתחום, נחוץ כדי להבין ולפתור בעיות מורכבות.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dependency</title>
      <link>https://smichaelshal.github.io/he/posts/models/dependency/</link>
      <pubDate>Sat, 16 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/dependency/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;תלות בין פעולות זיכרון קיימת כשביצוע פעולה אחת תלוי בתוצאת פעולה אחרת. תלות זו מתרחשת כאשר פעולה ראשונה (קריאה) מספקת ערך שמשפיע על התנהגות הפעולה השנייה (קריאה או כתיבה).&lt;/p&gt;&#xA;&lt;p&gt;כאשר קיימת פעולה של כתיבה שיש לה תלות סמנטית בקבוצה מסוימת של פעולות קריאה, חשוב שהכתיבה תתבצע רק לאחר שכל פעולות הקריאה הללו הושלמו. השלמת הקריאה מוגדרת כאן לפי פרספקטיבה של זמן גלובלי, כלומר, כתיבה תלויה לא יכולה להופיע כאילו בוצעה לפני סיום פעולת הקריאה האחרונה שעליה היא תלויה. משמעות הדבר היא שמודל הזיכרון חייב להבטיח שכתיבה כזו תשמור על סדר עקבי ביחס לקריאות שהשפיעו על ערכה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMBA ACE Barrier</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/amba-ace-barrier/</link>
      <pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/amba-ace-barrier/</guid>
      <description>&lt;h3 id=&#34;טרנזקציות-מחסום-בפרוטוקול-ace&#34;&gt;טרנזקציות מחסום בפרוטוקול ACE&lt;/h3&gt;&#xA;&lt;p&gt;פרוטוקול ACE תומך בטרנזקציות מחסום אשר משמשות להבטחת סדר והבחנה של טרנזקציות במערכת. המחסומים מסייעים ביצירת יחסי סדר בין פעולות, כדי להבטיח ביצועים ותאימות צפויה בין רכיבי המערכת.&lt;/p&gt;&#xA;&lt;p&gt;לצורך שימוש בטרנזקציות מחסום, רכיב מאסטר משתמש במאפייני דומיין השיתוף כדי להגדיר עם אילו רכיבים אחרים יש צורך לסנכרן את המחסום וכדי להקים יחסי סדר מוגדרים. הגדרת הדומיין של טרנזקציית המחסום מגדירה את מידת הפצת המחסום במערכת, ואילו מאפייני המחסום עצמם מכתיבים את יחסי הסדר הנדרשים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Acquire Release</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;מבוא&lt;/h1&gt;&#xA;&lt;p&gt;ההוראות מסוג load-acquire ו-store-release, כוללות מחסומים מובנים חד-כיווניים, המאפשרים דרישות סדר חלשות ממחסומים כלליים. הן משפיעות על הסדר של גישה לזיכרון מפורש שצוינו שנמצא בכל צד של הוראת מחסום הזיכרון. אופי זה מאפשר ביצועים משופרים בזכות אופטימיזציות מיקרו-ארכיטקטוניות ומצמצם את השפעת הביצועים לעומת מחסום זיכרון כללי.&lt;/p&gt;&#xA;&lt;p&gt;כאשר הסדר הנדרש נתמך על ידי load-acquire או store-release, מומלץ להשתמש בהן במקום במחסום כללי כדי לשפר את היעילות.&lt;/p&gt;&#xA;&lt;p&gt;סמנטיקות acquire ו-release הן מרכיבים חיוניים לאפשר העברת מידע מתואמת מ-thread אחד לאחר באופן אמין.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Herd7</title>
      <link>https://smichaelshal.github.io/he/posts/models/herd7/</link>
      <pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/herd7/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;אחת מהשיטות לפורמליזציה של מודל זיכרון היא ליצור תיאור מופשט שמתאר את האופן שבו מערכת פועלת בצורה פנימית. לאחר מכן, ניתן למנות את כל התוצאות האפשריות שנובעות מהפעולה המופשטת הזו. שיטה נוספת היא להגדיר את האילוצים שמטיל מודל הזיכרון בעזרת אקסיומות לוגיות, ולמיין את כל התוצאות האפשריות שמתאימות לאילוצים הללו, הכלי herd פועל לפי הגישה הזו.&lt;/p&gt;&#xA;&lt;p&gt;הכלי herd7 נועד לבדוק האם ביצועי זיכרון מסוימים, כולל תרחישים לא רצויים, יכולים להתרחש בתוכניות מקבילות בהתאם למודל זיכרון מוגדר. חשוב לציין כי herd7 עצמו אינו מתעסק ישירות בדרך שבה תוכניות רצות בפועל; הוא מתמקד אך ורק באימות התאמת הביצועים למודל הזיכרון שניתן לו.&lt;/p&gt;</description>
    </item>
    <item>
      <title>mb</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/mb/</link>
      <pubDate>Sat, 12 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/mb/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;מחסום זיכרון הוא הוראה המיועדת לאכוף מגבלות סדר על פעולות זיכרון המבוצעות לפני ואחרי הוראת המחסום. זה מתבטא בכך שפעולות זיכרון שביצוען סודר לפני המחסום יבוצעו לפני כל פעולות זיכרון שניתן להן לאחר המחסום.&lt;/p&gt;&#xA;&lt;p&gt;חשיבות האכיפה שהמחסומים מספקים נובעת מהעובדה שמעבדים והתקנים אחרים במערכת עשויים לנצל מגוון טכניקות לשיפור ביצועים, כמו שינוי סדר ההוראות, דחייה ושילוב של פעולות זיכרון, ביצוע loads ספקולטיביות, חיזוי ספקולטיבי של branch-ים ושימוש בסוגים שונים של cache. מחסומי זיכרון נועדו לעקוף או לדכא את הטכניקות הללו או את השפעותיהם, כך שהקוד יכול לשלוט בצורה צפויה באינטראקציות בין מספר מעבדים או בין מעבד למכשירים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Early Write Acknowledgment</title>
      <link>https://smichaelshal.github.io/he/posts/arm/early-write-acknowledgment/</link>
      <pubDate>Mon, 07 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/arm/early-write-acknowledgment/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בדרך כלל, אנו מצפים שבקשות invalidate יאושרו רק לאחר שכל העותקים הישנים של ה-cache line יוסרו מהיררכיית ה-cache של המעבד. בכך, האישור מעיד על כך שהכתיבה הסתיימה במלואה ביחס למעבד מסוים. עם זאת, כדי לצמצם את ההשהיה שנוצרת במהלך אישור כתיבות, במיוחד במערכות עם היררכיות cache עמוקות, נעשה שימוש באופטימיזציה נפוצה. אופטימיזציה זו מאשרת את בקשת ה-invalidate ברגע שהיא נכנסת לתור היררכיית ה-cache, עוד לפני שכל העותקים הישנים נמחקים בפועל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Domains</title>
      <link>https://smichaelshal.github.io/he/posts/arm/domains/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/arm/domains/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;הגישה לנתוני זיכרון עלולה להיות איטית יותר ולדרוש יותר כוח במערכות שבהן יש חומרת cache קוהרנטית, בהשוואה למערכות ללא מנגנון זה. כדי לצמצם את העלות הזו, נהוג לשמור על קוהרנטיות רק בין חלק מהרכיבים, תוך דאגה שהם ממוקמים קרוב פיזית זה לזה בתוך המעבד. לשם כך, ארכיטקטורת ARM מחלקת את המערכת לדומיינים, מה שמאפשר להגביל את הדרישה לקוהרנטיות רק לאזורים שבהם היא באמת נחוצה.&lt;/p&gt;&#xA;&lt;p&gt;המורכבות של פרוטוקולי קוהרנטיות cache משתנה בהתאם לחלקים של המערכת שבהם יש לשמור על סנכרון. בהתאם למבנה המערכת, פרוטוקול קוהרנטיות יכול להיות פשוט או מסובך.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speculation</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</guid>
      <description>&lt;h1 id=&#34;ספקולציות&#34;&gt;ספקולציות&lt;/h1&gt;&#xA;&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;ביצוע ספקולטיבי הוא שיטת אופטימיזציה במערכות מחשב, שבה מבוצעות משימות מראש, לפני שנודע בוודאות אם הן נדרשות. המטרה היא לחסוך זמן ולמנוע עיכובים בביצוע העבודה לאחר שמתברר שהיא נדרשת. אם בסופו של דבר מתברר שהמשימה לא הייתה הכרחית, המערכת מבטלת את רוב השינויים שבוצעו ומתעלמת מתוצאות הביצוע.&lt;/p&gt;&#xA;&lt;p&gt;מטרת הביצוע הספקולטיבי היא להגדיל את ניצול המשאבים במערכת ולהפחית עיכובים. השיטה משמשת בתחומים רבים, כמו חיזוי נתיבי branch במעבדים עם pipeline, חיזוי ערכי נתונים לניצול מקומיות ערכית, ושליפת נתונים מראש מהזיכרון.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache maintenance</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</guid>
      <description>&lt;h2 id=&#34;תחזוקת-cache-בתוכנה&#34;&gt;תחזוקת cache בתוכנה&lt;/h2&gt;&#xA;&lt;p&gt;לעיתים יש צורך בתוכנה לבצע פעולות ניקוי או ביטול של ה-cache. פעולות אלו נדרשות כאשר תוכן הזיכרון החיצוני השתנה, ויש צורך להבטיח שה-cache אינו מכיל נתונים מיושנים. פעולות אלו יכולות להיות נדרשות גם לאחר שינויים הקשורים ל-MMU כמו שינוי הרשאות גישה, מדיניות cache, מיפוי כתובות וירטואליות לכתובת פיזית, או כאשר ה-I-caches ו-D-caches חייבים להיות מסונכרנים לקוד שנוצר באופן דינמי, כגון ב-JIT-compilers וטועני ספריות דינמיות.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ביטול (Invalidation) של cache או cache line: פעולה זו כוללת ניקוי של ה-cache מנתונים ללא כתיבה לרמה הבאה או לזיכרון הראשי על ידי ביטול של cache line אחת או יותר. משמעות הדבר היא שה-cache מסומן כ-invalid, ולכן תוכן השורות אינו מוגדר. אפשר לראות זאת כדרך להסיר שינויים בתחום הזיכרון מה-cache, כך שהנתונים המחודשים מהזיכרון החיצוני יכנסו ל-cache בצורה נכונה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMBA CHI</title>
      <link>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/amba-chi/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/amba-chi/</guid>
      <description>&lt;h3 id=&#34;מהו-amba&#34;&gt;מהו AMBA?&lt;/h3&gt;&#xA;&lt;p&gt;פרוטוקול AMBA (קיצור של Advanced Microcontroller Bus Architecture) הוא פרוטוקול שפותח על ידי ARM ומיועד לסטנדרטיזציה של התקשורת בין רכיבי חומרה שונים במערכות SoC. משפחת פרוטוקולים זו מכסה מגוון רחב של היבטים בתכנון המערכת, כולל טופולוגיית bus, בוררות (arbitration) בין רכיבים המבקשים גישה למשאבים משותפים, ניהול signaling, תכנון interconnect, ניהול צריכת חשמל ואבטחה. הפרוטוקול AMBA כולל מספר מפרטים שונים שמותאמים לצרכים מגוונים של טרנזקציות וסוכנים במערכת, כולל AHB, APB, AXI, ACE ו-CHI. כל אחד מפרוטוקולים אלו מתמקד בהיבט מסוים של התקשורת בין רכיבי המערכת.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;זיכרון RAM מהיר כמו ליבות המעבד המודרניות יקר בהרבה לעומת זיכרון DRAM הקונבנציונלי. העלויות הגבוהות של זיכרון מהיר נוטות להיות מנוטרלות על ידי התקורות הכרוכות בניהול המשאבים. לכן, במקום להפוך את ה-SRAM למשאב שנשלט על ידי מערכת ההפעלה או המשתמש, הוא מנוהל ישירות על ידי המעבד, והשימוש בו שקוף למערכת.&lt;/p&gt;&#xA;&lt;p&gt;במקרה כזה, ה-SRAM משמש כזיכרון cache, כלומר, כמאגר זמני עבור נתונים מהזיכרון הראשי, אשר סביר להניח שיעשה בהם שימוש בקרוב על ידי המעבד. הדבר מתאפשר בזכות העובדה שהקוד והנתונים של תוכנה נוטים להפגין מקומיות זמנית ומרחבית.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combined buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בגלל שלקריאה וכתיבה לזיכרון חיצוני עלולה להיות זמן השהייה ממושך, מעבדים יכולים לצמצם את מספר ההעברות על ידי מיזוג מספר כתיבות (stores) לטרנזקציה אחת גדולה יותר. על ידי כך, המעבד מבצע את הכתיבות כפעולה אחת מרוכזת, מה שמפחית את העומס על ה-bus ושיפור היעילות של הגישה לזיכרון החיצוני.&lt;/p&gt;&#xA;&lt;p&gt;שילוב כתיבה הוא אופטימיזציה שמטרתה לצמצם את כמות ההעברות בין ה-cache למכשירים, במיוחד במצבים שבהם עלויות ההעברה גבוהות משמעותית מהגישה המקומית ל-RAM. לדוגמה, בכרטיסים גרפיים, שעלויות ההעברה למכשירים גבוהות הרבה יותר. לכן, יש להימנע מהעברות מיותרות. אם יש צורך להעביר שורת cache שלמה רק בגלל שכתיבה אחת שונתה, זו פעולה בזבזנית, במיוחד אם הפעולה הבאה משנה מילה נוספת באותה השורה. בהתאם לכך, שילוב כתיבה אוסף מספר שינויים לפני שכותב את שורת ה-cache למכשיר. במצבים אידיאליים, כל מילה בשורת ה-cache משתנה אחת אחרי השנייה ורק לאחר שהמילה האחרונה השתנתה, שורת ה-cache נכתבת למכשיר.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fetch</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/fetch/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/fetch/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;מבוא&lt;/h1&gt;&#xA;&lt;h2 id=&#34;שליפה-מוקדמת&#34;&gt;שליפה מוקדמת&lt;/h2&gt;&#xA;&lt;p&gt;מטרת השליפה המוקדמת היא להפחית את זמן ההשהיה של גישה לזיכרון. למרות שה-pipeline של ההוראות ויכולת הביצוע מחוץ לסדר (out-of-order) של מעבדים מודרניים יכולים להפחית חלק מהשהיית הזיכרון, זה מוגבל בעיקר לגישות שהן cache hit. כדי לכסות את כל זמן האחזור של גישה לזיכרון הראשי, ה-pipeline היה צריך להיות ארוך מאוד, מה שלא פרקטי. חלק מהמעבדים שאינם תומכים בביצוע מחוץ לסדר מנסים לפצות על כך באמצעות הגדלת מספר הליבות, אך זה יעיל רק אם כל הקוד יכול לפעול במקביל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uops</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/uops/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/uops/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים, micro-operations (המכונות גם micro-ops או μops, ובאופן היסטורי micro-actions) הן הוראות ברמה נמוכה המשמשות ליישום הוראות מכונה מורכבות בעיצובים מסוימים (לעיתים מכונות פקודות מאקרו בהקשר זה).&lt;/p&gt;&#xA;&lt;p&gt;בדרך כלל, micro-operations מבצעות פעולות בסיסיות על נתונים המאוחסנים ברגיסטר אחד או יותר, כמו העברת נתונים בין רגיסטרים או בין רגיסטרים לבין bus-ים חיצוניים של המעבד (CPU), וכן ביצוע פעולות אריתמטיות או לוגיות על הנתונים ברגיסטרים. במחזור fetch -&amp;gt; decode -&amp;gt; execute טיפוסי, כל שלב בהוראת מאקרו מתפרק במהלך הביצוע, כך שהמעבד קובע ומבצע סדרה של micro-operations. הביצוע של micro-operations מתבצע תחת שליטת יחידת הבקרה של המעבד, אשר מבצעת אופטימיזציות שונות כמו סידור מחדש, היתוך ואחסון ב-cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exclusive</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/exclusive/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/exclusive/</guid>
      <description>&lt;h2 id=&#34;load-lockstore-conditional-llsc&#34;&gt;Load Lock/Store Conditional (LL/SC)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;load-lockstore-conditional&#34;&gt;Load-Lock/Store-Conditional&lt;/h3&gt;&#xA;&lt;p&gt;ה-Load-Lock ו-Store-Conditional נקרא גם Load-Link/Store-Conditional הן צמד הוראות המשמשות ב-multithreading כדי להשיג סנכרון בין thread-ים.&lt;/p&gt;&#xA;&lt;p&gt;ההוראה Load-Lock (או בקיצור LL) משמשת לקרוא את הערך הנוכחי במיקום זיכרון,  ההוראה רושמת באופן פנימי (למשל ב-arm המידע נשמר ב- exclusive monitors) את מיקום הזיכרון לצורך גישה בלעדית, בעוד שההוראה Store-Conditional (או בקיצור SC) נועדה לשמור ערך חדש באותו מיקום זיכרון, אך רק אם לא התרחשו שינויים באותו מיקום זיכרון מאז ההוראת ה-LL התואמת הקודמת.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Atomic</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/atomic/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/atomic/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;כאשר מספר thread-ים מנסים לשנות בו-זמנית את אותו מיקום בזיכרון, המעבדים אינם מבטיחים תוצאה ספציפית כלשהי כתוצאה מהפעולה.&lt;/p&gt;&#xA;&lt;p&gt;כשאנחנו אומרים שעדכון מסוג RMW, כמו למשל &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt;, הוא אטומי, הכוונה היא לכך שמיקום הזיכרון (במקרה הזה, &lt;code&gt;x&lt;/code&gt;) לא ישתנה בין שלבי הקריאה והכתיבה שמרכיבים את הפעולה האטומית. במילים אחרות, אם שני מעבדים מבצעים את &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt; במקביל, יש לוודא שהערך הסופי של &lt;code&gt;x&lt;/code&gt; יהיה הערך ההתחלתי בתוספת 2.&#xA;אין מצב שבו ניתן יהיה לקבל רצף אירועים כזה:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
