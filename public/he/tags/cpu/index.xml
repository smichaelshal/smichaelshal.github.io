<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cpu on Michael Shalitin</title>
    <link>https://smichaelshal.github.io/he/tags/cpu/</link>
    <description>Recent content in Cpu on Michael Shalitin</description>
    <generator>Hugo</generator>
    <language>he</language>
    <lastBuildDate>Sat, 21 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://smichaelshal.github.io/he/tags/cpu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Causal &amp; Physics</title>
      <link>https://smichaelshal.github.io/he/posts/causal--physics/</link>
      <pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/causal--physics/</guid>
      <description>&lt;h2 id=&#34;ראייה-מורכבת-יותר-של-זיכרון&#34;&gt;ראייה מורכבת יותר של זיכרון&lt;/h2&gt;&#xA;&lt;p&gt;מערכות מחשוב מודרניות מספקות אופטימיזציות וביצועים גבוהים אבל זה לא מגיע בחינם, כל אלה גורמים לסיבוך משמעותי, ולכן הרבה פעמים משתמשים בכלים שגורמים לכל הסיבוך הזה להיות שקוף כלפי המשתמש כמו שפות high level,  מנגנוני נעילה וכל מיני מנגנונים אחרים.&lt;/p&gt;&#xA;&lt;p&gt;בצורה הזאת אפשר לדמות שפות high level ומנגנוני נעילה למערכת שמתפקדת על פי עקרונות של פיזיקה ניוטונית: כשיש נעילה, המערכת מתנהגת בצורה דטרמיניסטית וצפויה, וניתן לדעת בוודאות מה יתרחש בכל מצב נתון. לעומת זאת, במעבר לרמות נמוכות יותר של ניהול זיכרון (למשל, ניהול זיכרון במערכות מרובות ליבות ללא נעילה), המצב מתחיל להזכיר את עקרונות הפיזיקה הקוונטית, שבהם אירועים מפתיעים יכולים להתרחש, וההבנה המלאה של התהליכים מורכבת יותר. רק מעטים יטענו שהם מבינים את כל ההתרחשויות בעולם הזה. אמנם לרוב ניתן לפעול היטב בסביבה זו מבלי להבין את הפרטים המורכבים, אך ישנם מקרים שבהם ידע מעמיק בתחום, נחוץ כדי להבין ולפתור בעיות מורכבות.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LKMM Code Examples</title>
      <link>https://smichaelshal.github.io/he/posts/models/lkmm-code-examples/</link>
      <pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/lkmm-code-examples/</guid>
      <description>&lt;h2 id=&#34;שימוש-במחסומי-זיכרון-עם-buffer-ים-מעגליים&#34;&gt;שימוש במחסומי זיכרון עם buffer-ים מעגליים&lt;/h2&gt;&#xA;&lt;p&gt;שימוש במחסומי זיכרון בשילוב עם buffer-ים מעגליים מאפשר התמודדות עם בעיות סינכרון בצורה יעילה יותר, תוך הימנעות מהצורך במנגנונים כבדים כמו:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;המנעות מנעילה:&lt;/strong&gt; במקום להשתמש במנעול ששולט על שני הקצוות של ה-buffer (הקצה של הכתיבה והקצה של הקריאה), ניתן לאפשר גישה בו-זמנית לשני הצדדים. כך היצרן יכול להכניס נתונים ל-buffer בו זמנית עם הצרכן שמוציא נתונים ממנו, מבלי להשתמש במנעול.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;המנעות מ-counter אטומי:&lt;/strong&gt; אין צורך להשתמש בפעולות מונה אטומיות לניהול מצב ה-buffer (כגון ספירת מספר הפריטים או מעקב אחרי המיקום הנוכחי לכתיבה ולקריאה).&lt;/p&gt;</description>
    </item>
    <item>
      <title>LKMM</title>
      <link>https://smichaelshal.github.io/he/posts/models/lkmm/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/lkmm/</guid>
      <description>&lt;h1 id=&#34;קבצי-המודל&#34;&gt;קבצי המודל&lt;/h1&gt;&#xA;&lt;h2 id=&#34;מילון&#34;&gt;מילון&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;LKR&lt;/code&gt; - Lock-Read&#xA;&lt;code&gt;LKW&lt;/code&gt; - Lock-Write&#xA;&lt;code&gt;UL&lt;/code&gt; - Unlock&#xA;&lt;code&gt;LF&lt;/code&gt; - Lock-Fail&#xA;&lt;code&gt;RL&lt;/code&gt; - Read-Locked&#xA;&lt;code&gt;RU&lt;/code&gt; - Read-Unlocked&#xA;&lt;code&gt;ilb&lt;/code&gt; - idle load balancer&lt;/p&gt;&#xA;&lt;h2 id=&#34;הקובץ-linux-kernelbell&#34;&gt;הקובץ &lt;code&gt;linux-kernel.bell&lt;/code&gt;&lt;/h2&gt;&#xA;&lt;p&gt;בקובץ &lt;code&gt;tools/memory-model/linux-kernel.bell&lt;/code&gt; מוגדרים מספר הגדרות מעניינות:&lt;/p&gt;&#xA;&lt;h3 id=&#34;תיוג-אירועים&#34;&gt;תיוג אירועים&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;enum&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Accesses&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;once&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*READ_ONCE,WRITE_ONCE*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 2&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;release&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_store_release*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 3&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;acquire&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_load_acquire*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 4&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;noreturn&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(* R of non-return RMW *)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 5&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;instructions&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;R&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;once&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;acquire&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;noreturn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 6&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;instructions&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;once&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 7&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;instructions&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;RMW&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;once&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;acquire&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;}]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 8&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt; 9&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;enum&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Barriers&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wmb&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_wmb*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rmb&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_rmb*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mb&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;barrier&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*barrier*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rcu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lock&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*rcu_read_lock*)&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;14&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rcu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*rcu_read_unlock*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rcu&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*synchronize_rcu*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;before&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;atomic&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb__before_atomic*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;after&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;atomic&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb__after_atomic*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;after&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;spinlock&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb__after_spinlock*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;19&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;after&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lock&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb__after_unlock_lock*)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;&#x9;&lt;span class=&#34;k&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;after&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;srcu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unlock&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;(*smp_mb__after_srcu_read_unlock*)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;ln&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;instructions&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Barriers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;כאן מגדירים תגים לאירועים (האירועים מוגדרים ומתויגים ב-&lt;code&gt;tools/memory-model/linux-kernel.def&lt;/code&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dependency</title>
      <link>https://smichaelshal.github.io/he/posts/models/dependency/</link>
      <pubDate>Sat, 16 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/dependency/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;תלות בין פעולות זיכרון קיימת כשביצוע פעולה אחת תלוי בתוצאת פעולה אחרת. תלות זו מתרחשת כאשר פעולה ראשונה (קריאה) מספקת ערך שמשפיע על התנהגות הפעולה השנייה (קריאה או כתיבה).&lt;/p&gt;&#xA;&lt;p&gt;כאשר קיימת פעולה של כתיבה שיש לה תלות סמנטית בקבוצה מסוימת של פעולות קריאה, חשוב שהכתיבה תתבצע רק לאחר שכל פעולות הקריאה הללו הושלמו. השלמת הקריאה מוגדרת כאן לפי פרספקטיבה של זמן גלובלי, כלומר, כתיבה תלויה לא יכולה להופיע כאילו בוצעה לפני סיום פעולת הקריאה האחרונה שעליה היא תלויה. משמעות הדבר היא שמודל הזיכרון חייב להבטיח שכתיבה כזו תשמור על סדר עקבי ביחס לקריאות שהשפיעו על ערכה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMBA ACE Barrier</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/amba-ace-barrier/</link>
      <pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/amba-ace-barrier/</guid>
      <description>&lt;h3 id=&#34;טרנזקציות-מחסום-בפרוטוקול-ace&#34;&gt;טרנזקציות מחסום בפרוטוקול ACE&lt;/h3&gt;&#xA;&lt;p&gt;פרוטוקול ACE תומך בטרנזקציות מחסום אשר משמשות להבטחת סדר והבחנה של טרנזקציות במערכת. המחסומים מסייעים ביצירת יחסי סדר בין פעולות, כדי להבטיח ביצועים ותאימות צפויה בין רכיבי המערכת.&lt;/p&gt;&#xA;&lt;p&gt;לצורך שימוש בטרנזקציות מחסום, רכיב מאסטר משתמש במאפייני דומיין השיתוף כדי להגדיר עם אילו רכיבים אחרים יש צורך לסנכרן את המחסום וכדי להקים יחסי סדר מוגדרים. הגדרת הדומיין של טרנזקציית המחסום מגדירה את מידת הפצת המחסום במערכת, ואילו מאפייני המחסום עצמם מכתיבים את יחסי הסדר הנדרשים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Acquire Release</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;מבוא&lt;/h1&gt;&#xA;&lt;p&gt;ההוראות מסוג load-acquire ו-store-release, כוללות מחסומים מובנים חד-כיווניים, המאפשרים דרישות סדר חלשות ממחסומים כלליים. הן משפיעות על הסדר של גישה לזיכרון מפורש שצוינו שנמצא בכל צד של הוראת מחסום הזיכרון. אופי זה מאפשר ביצועים משופרים בזכות אופטימיזציות מיקרו-ארכיטקטוניות ומצמצם את השפעת הביצועים לעומת מחסום זיכרון כללי.&lt;/p&gt;&#xA;&lt;p&gt;כאשר הסדר הנדרש נתמך על ידי load-acquire או store-release, מומלץ להשתמש בהן במקום במחסום כללי כדי לשפר את היעילות.&lt;/p&gt;&#xA;&lt;p&gt;סמנטיקות acquire ו-release הן מרכיבים חיוניים לאפשר העברת מידע מתואמת מ-thread אחד לאחר באופן אמין.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Herd7</title>
      <link>https://smichaelshal.github.io/he/posts/models/herd7/</link>
      <pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/herd7/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;אחת מהשיטות לפורמליזציה של מודל זיכרון היא ליצור תיאור מופשט שמתאר את האופן שבו מערכת פועלת בצורה פנימית. לאחר מכן, ניתן למנות את כל התוצאות האפשריות שנובעות מהפעולה המופשטת הזו. שיטה נוספת היא להגדיר את האילוצים שמטיל מודל הזיכרון בעזרת אקסיומות לוגיות, ולמיין את כל התוצאות האפשריות שמתאימות לאילוצים הללו, הכלי herd פועל לפי הגישה הזו.&lt;/p&gt;&#xA;&lt;p&gt;הכלי herd7 נועד לבדוק האם ביצועי זיכרון מסוימים, כולל תרחישים לא רצויים, יכולים להתרחש בתוכניות מקבילות בהתאם למודל זיכרון מוגדר. חשוב לציין כי herd7 עצמו אינו מתעסק ישירות בדרך שבה תוכניות רצות בפועל; הוא מתמקד אך ורק באימות התאמת הביצועים למודל הזיכרון שניתן לו.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Models</title>
      <link>https://smichaelshal.github.io/he/posts/models/models/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/models/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;מחשבים, בהיותם אוטומטים דטרמיניסטיים, בדרך כלל יניבו התנהגות צפויה ואחידה, ולכן רוב האנשים יחשבו שגזירת התוצאה היא אחת בלבד. עבור מערכות חד-מעבדים, רוב הזמן הם יהיו נכונים בהנחה הזו. עם זאת, במערכות מרובות מעבדים, התמונה משתנה, והן יכולות להוביל למגוון רחב הרבה יותר של התנהגויות. זאת בשל שינויים עדינים בתזמון היחסי של המעבדים השונים במערכת, כמו גם השפעת האותות המועברים ביניהם, ה-cache-ים והזיכרון הראשי.&lt;/p&gt;&#xA;&lt;p&gt;מודלים של זיכרון מנסים להביא סדר לתמונה הזו, וזאת בעיקר על ידי תיאור מדויק של אילו תוצאות אפשריות עשויות להתרחש במערכת מרובת מעבדים SMP שמריצה תוכנית מסוימת. מטרת המודל היא להבהיר את התוצאה הצפויה מהפעולות המבוצעות, ולהגביל את האפשרויות באופן שיקל על ניתוח התנהגות המערכת.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Base Formal</title>
      <link>https://smichaelshal.github.io/he/posts/models/base-formal/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/base-formal/</guid>
      <description>&lt;h2 id=&#34;יחסי-סדר&#34;&gt;יחסי סדר&lt;/h2&gt;&#xA;&lt;p&gt;מודלי זיכרון עוסקים בקביעת סדר, לרוב סדר זמני שבו אירועים מתרחשים, אך לא בהכרח רק בכך. לדוגמה, ניתן להתייחס גם לסדר ההוראות בקוד המקור של תוכנית. המודל SC מניח כי המעבדים מבצעים את ההוראות באותו סדר שבו הן מופיעות בקוד המקור, דבר שמדגיש את חשיבות הסדר. בנוסף לכך, הסדר ממלא תפקיד מרכזי במודלי זיכרון שונים.&lt;/p&gt;&#xA;&lt;p&gt;רעיון מקביל לסדר הוא הרעיון של מחזורים (cycle) - סידור אירועים פוסל מחזורים, שכן לא ניתן לסדר אירועים כך שאירוע X יופיע לפני Y, אירוע Y לפני Z, ואירוע Z יופיע לפני X, שכן זה יגרום לכך ש-X יופיע לפני עצמו, מה שאינו אפשרי.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ordering</title>
      <link>https://smichaelshal.github.io/he/posts/models/ordering/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/ordering/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים מודרניים ישנן הוראות רבות שלא ניתן להשלים מיידית, מאחר והן דורשות זמן לביצוע (מספר מחזורי שעון).&lt;/p&gt;&#xA;&lt;p&gt;במצב זה, ביצוע in-order משמעו שהמעבד ימתין בכל פעם שהוראה דורשת נתונים חסרים או שהיא אורכת מספר מחזורים לביצוע, מה שמוביל לעיכובים (stalls) בתהליך העיבוד.&lt;/p&gt;&#xA;&lt;p&gt;לעומת זאת, בביצוע out-of-order, נעשה שימוש בטכניקות מתקדמות למעקב אחר נתונים. כאשר הוראה מסוימת אינה יכולה להתבצע בשל חוסר בנתונים, המעבד לא נכנס למצב של stall, אלא מריץ הוראות אחרות, כל עוד אין תלות ישירה בינן לבין ההוראות שטרם הושלמו. כך המעבד מנצל ביעילות את זמנו הפנוי וממשיך לעבד הוראות שאינן דורשות המתנה לנתונים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>mb</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/mb/</link>
      <pubDate>Sat, 12 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/mb/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;מחסום זיכרון הוא הוראה המיועדת לאכוף מגבלות סדר על פעולות זיכרון המבוצעות לפני ואחרי הוראת המחסום. זה מתבטא בכך שפעולות זיכרון שביצוען סודר לפני המחסום יבוצעו לפני כל פעולות זיכרון שניתן להן לאחר המחסום.&lt;/p&gt;&#xA;&lt;p&gt;חשיבות האכיפה שהמחסומים מספקים נובעת מהעובדה שמעבדים והתקנים אחרים במערכת עשויים לנצל מגוון טכניקות לשיפור ביצועים, כמו שינוי סדר ההוראות, דחייה ושילוב של פעולות זיכרון, ביצוע loads ספקולטיביות, חיזוי ספקולטיבי של branch-ים ושימוש בסוגים שונים של cache. מחסומי זיכרון נועדו לעקוף או לדכא את הטכניקות הללו או את השפעותיהם, כך שהקוד יכול לשלוט בצורה צפויה באינטראקציות בין מספר מעבדים או בין מעבד למכשירים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Early Write Acknowledgment</title>
      <link>https://smichaelshal.github.io/he/posts/arm/early-write-acknowledgment/</link>
      <pubDate>Mon, 07 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/arm/early-write-acknowledgment/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בדרך כלל, אנו מצפים שבקשות invalidate יאושרו רק לאחר שכל העותקים הישנים של ה-cache line יוסרו מהיררכיית ה-cache של המעבד. בכך, האישור מעיד על כך שהכתיבה הסתיימה במלואה ביחס למעבד מסוים. עם זאת, כדי לצמצם את ההשהיה שנוצרת במהלך אישור כתיבות, במיוחד במערכות עם היררכיות cache עמוקות, נעשה שימוש באופטימיזציה נפוצה. אופטימיזציה זו מאשרת את בקשת ה-invalidate ברגע שהיא נכנסת לתור היררכיית ה-cache, עוד לפני שכל העותקים הישנים נמחקים בפועל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Domains</title>
      <link>https://smichaelshal.github.io/he/posts/arm/domains/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/arm/domains/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;הגישה לנתוני זיכרון עלולה להיות איטית יותר ולדרוש יותר כוח במערכות שבהן יש חומרת cache קוהרנטית, בהשוואה למערכות ללא מנגנון זה. כדי לצמצם את העלות הזו, נהוג לשמור על קוהרנטיות רק בין חלק מהרכיבים, תוך דאגה שהם ממוקמים קרוב פיזית זה לזה בתוך המעבד. לשם כך, ארכיטקטורת ARM מחלקת את המערכת לדומיינים, מה שמאפשר להגביל את הדרישה לקוהרנטיות רק לאזורים שבהם היא באמת נחוצה.&lt;/p&gt;&#xA;&lt;p&gt;המורכבות של פרוטוקולי קוהרנטיות cache משתנה בהתאם לחלקים של המערכת שבהם יש לשמור על סנכרון. בהתאם למבנה המערכת, פרוטוקול קוהרנטיות יכול להיות פשוט או מסובך.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speculation</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</guid>
      <description>&lt;h1 id=&#34;ספקולציות&#34;&gt;ספקולציות&lt;/h1&gt;&#xA;&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;ביצוע ספקולטיבי הוא שיטת אופטימיזציה במערכות מחשב, שבה מבוצעות משימות מראש, לפני שנודע בוודאות אם הן נדרשות. המטרה היא לחסוך זמן ולמנוע עיכובים בביצוע העבודה לאחר שמתברר שהיא נדרשת. אם בסופו של דבר מתברר שהמשימה לא הייתה הכרחית, המערכת מבטלת את רוב השינויים שבוצעו ומתעלמת מתוצאות הביצוע.&lt;/p&gt;&#xA;&lt;p&gt;מטרת הביצוע הספקולטיבי היא להגדיל את ניצול המשאבים במערכת ולהפחית עיכובים. השיטה משמשת בתחומים רבים, כמו חיזוי נתיבי branch במעבדים עם pipeline, חיזוי ערכי נתונים לניצול מקומיות ערכית, ושליפת נתונים מראש מהזיכרון.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Store buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;המעבדים היום הרבה יותר מהירים מהזיכרון הראשי ולכן כל גישה לזיכרון יכולה לגרום לעיכוב משמעותי בביצועי המעבד ולכן מעבדים מנסים לצמצם ככל הניתן את העיכוב הזה, ולכן פותחו טכניקות שמנסות לנתק כמה שניתן את ביצועי המעבד מהזיכרון עצמו, כמו cache-ים וכל מיני סוגי buffer-ים יעודיים.&lt;/p&gt;&#xA;&lt;p&gt;אחד ה-buffer-ים המרכזיים הוא ה-store buffer (ידוע גם כ-write buffer) והמטרה שלו היא לנתק את ביצוע הכתיבה של המעבד.&lt;/p&gt;&#xA;&lt;p&gt;ה-store buffer מאפשר למעבד לשגר את הוראת הכתיבה ואז הוא יכול &amp;ldquo;לשכוח&amp;rdquo; מהכתיבה וכל האחריות של ביצוע הכתיבה וכל מה שכרוך בה עוברת ל-store buffer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Register renaming</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/register-renaming/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/register-renaming/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בארכיטקטורת מחשבים, Register Renaming הוא טכניקה שמבצעת הפרדה בין רגיסטרים לוגיים לרגיסטרים פיזיים. כל רגיסטר לוגי מקושר לקבוצה של רגיסטרים פיזיים, וכאשר הוראת שפת מכונה מתייחסת לרגיסטר לוגי, המעבד ממפה אותו לרגיסטר פיזי ספציפי במהלך הביצוע. הרגיסטרים הפיזיים אינם נגישים ישירות, וניתן לגשת אליהם רק דרך השמות הקנוניים של הרגיסטרים הלוגיים.&lt;/p&gt;&#xA;&lt;p&gt;טכניקה זו מאפשרת להתגבר על תלות כוזבת בנתונים הנובעת משימוש חוזר ברגיסטרים על ידי הוראות עוקבות שאין ביניהן תלות אמיתית. ביטול התלות הכוזבת מגביר את המקבילות ברמת ההוראה בזרם הפקודות, מה שמאפשר לנצל טכניקות כמו ביצוע על-סקלרי וביצוע מחוץ לסדר לשיפור הביצועים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multi-copy atomicity</title>
      <link>https://smichaelshal.github.io/he/posts/cache/multi-copy-atomicity/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/multi-copy-atomicity/</guid>
      <description>&lt;h2 id=&#34;דרישת-אטומיות&#34;&gt;דרישת אטומיות&lt;/h2&gt;&#xA;&lt;p&gt;שמירה ב-cache של נתונים משותפים מהווה אופטימיזציה חשובה שמסייעת להפחית את זמן השהייה של גישות לזיכרון במערכות זיכרון משותף. אולם, שמירה ב-cache יוצרת מספר עותקים של נתונים בצמתים שונים ברשת, והצורך לשמור על עדכניות העותקים הללו בכל כתיבה יכול להוות אתגר. קיימת האפשרות לבטל את העותקים הישנים או לעדכן אותם לערך החדש. אך הפצת העותקים והשוני במסלולי הרשת מקשים על ביטול או עדכון של העותקים בצורה אטומית.&lt;/p&gt;&#xA;&lt;p&gt;לרוב יש פתרונות אפקטיביים לדרישת אטומיות עבור מערכות המשתמשות ב-invalidating. פתרונות למערכות המשתמשות ב-updating נוטים להיות מסובכים ובלתי יעילים לעומת הפתרונות ל-invalidating.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pipeline &amp; Hazard</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/pipeline--hazard/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/pipeline--hazard/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;טכניקה נפוצה במעבדים מודרנים היא pipeline, הטכניקה מאפשרת הרצה של הוראות לא תלויות בו זמנית (concurrency) והיא מאפשרת שיפור ביצועים של המעבד.&lt;/p&gt;&#xA;&lt;p&gt;הרעיון ב-pipeline הוא שכל הוראה בודדת מורכבת מכמה פעולות שניתן להפריד, ולכל סוג של פעולה כזאת יכול להיות רכיב אחר שמטפל בה, וככה ניתן להתחיל את ההוראה הבאה לביצוע עוד לפני שההוראה הקודמת הסתיימה.&lt;/p&gt;&#xA;&lt;p&gt;הטכניקה מזכירה את שיטת פס ייצור, בפס ייצור אין מכונה או אדם בודד שמייצרים את המוצר מהתחלה ועד הסוף, כל רכיב אחרי רק על פעולה אחת בודדת ופשוטה יחסית וכל הפעולות האלו מתרחשות בו זמנית.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache maintenance</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</guid>
      <description>&lt;h2 id=&#34;תחזוקת-cache-בתוכנה&#34;&gt;תחזוקת cache בתוכנה&lt;/h2&gt;&#xA;&lt;p&gt;לעיתים יש צורך בתוכנה לבצע פעולות ניקוי או ביטול של ה-cache. פעולות אלו נדרשות כאשר תוכן הזיכרון החיצוני השתנה, ויש צורך להבטיח שה-cache אינו מכיל נתונים מיושנים. פעולות אלו יכולות להיות נדרשות גם לאחר שינויים הקשורים ל-MMU כמו שינוי הרשאות גישה, מדיניות cache, מיפוי כתובות וירטואליות לכתובת פיזית, או כאשר ה-I-caches ו-D-caches חייבים להיות מסונכרנים לקוד שנוצר באופן דינמי, כגון ב-JIT-compilers וטועני ספריות דינמיות.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;ביטול (Invalidation) של cache או cache line: פעולה זו כוללת ניקוי של ה-cache מנתונים ללא כתיבה לרמה הבאה או לזיכרון הראשי על ידי ביטול של cache line אחת או יותר. משמעות הדבר היא שה-cache מסומן כ-invalid, ולכן תוכן השורות אינו מוגדר. אפשר לראות זאת כדרך להסיר שינויים בתחום הזיכרון מה-cache, כך שהנתונים המחודשים מהזיכרון החיצוני יכנסו ל-cache בצורה נכונה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Snoop &amp; Directory</title>
      <link>https://smichaelshal.github.io/he/posts/cache/snoop--directory/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/snoop--directory/</guid>
      <description>&lt;h2 id=&#34;פרוטוקול-snooping&#34;&gt;פרוטוקול Snooping&lt;/h2&gt;&#xA;&lt;p&gt;מנגנון Snooping הוא מנגנון שבו כל אחד מה-cache-ים במערכת עוקב אחרי שורות כתובת מסוימות כדי לזהות אם שורות זיכרון ששמורות ב-cache שלו נגישות או משתנות על ידי מעבדים אחרים. פרוטוקולי קוהרנטיות כמו פרוטוקולי invalidate ופרוטוקולי update משתמשים במנגנון זה.&lt;/p&gt;&#xA;&lt;p&gt;פרוטוקול snooping מתבסס על bus משותף שמחבר בין כל ה-cache-ים לבין הזיכרון הראשי. כאשר מעבד מבצע כתיבה ל-cache שלו, הוא משדר את הכתובת של הבלוק שעבר שינוי אל ה-bus. מעבדים אחרים שברשותם עותק של אותו הבלוק ב-cache יכולים לבחור לבטל את העותק או לעדכן אותו, תלוי בגרסת הפרוטוקול שנמצאת בשימוש פרוטוקול מבוסס invalidate או מבוסס update). היתרון העיקרי של פרוטוקול זה הוא הפשטות והמהירות שלו, אך הוא מגיע עם מספר חסרונות:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache coherence</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache-coherence/</link>
      <pubDate>Sun, 15 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache-coherence/</guid>
      <description>&lt;hr&gt;&#xA;&lt;h2 id=&#34;מבוא-לקוהרנטיות&#34;&gt;מבוא לקוהרנטיות&lt;/h2&gt;&#xA;&lt;p&gt;בעיית קוהרנטיות יכולה להתרחש כאשר מספר גורמים (כמו מספר ליבות) מנסים לגשת לנתון מסוים שיש לו מספר עותקים (למשל, עותקים שונים ב-cache-ים) ולפחות אחת הגישות היא כתיבה. כדי למנוע גישה לנתונים מיושנים (שגורמת לחוסר קוהרנטיות) נעשה שימוש בפרוטוקול קוהרנטיות.&lt;/p&gt;&#xA;&lt;p&gt;חוסר קוהרנטיות נגרם בעיקר בשל נוכחותם של מספר מעבדים עם גישה ל-cache-ים ולזיכרון. במערכות מודרניות, מעבדים אלו כוללים ליבות מעבד, מנועי DMA  והתקנים חיצוניים, אשר יכולים לקרוא ולכתוב לזיכרון ולפחות לחלקם יש cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMBA CHI</title>
      <link>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/amba-chi/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/amba-chi/</guid>
      <description>&lt;h3 id=&#34;מהו-amba&#34;&gt;מהו AMBA?&lt;/h3&gt;&#xA;&lt;p&gt;פרוטוקול AMBA (קיצור של Advanced Microcontroller Bus Architecture) הוא פרוטוקול שפותח על ידי ARM ומיועד לסטנדרטיזציה של התקשורת בין רכיבי חומרה שונים במערכות SoC. משפחת פרוטוקולים זו מכסה מגוון רחב של היבטים בתכנון המערכת, כולל טופולוגיית bus, בוררות (arbitration) בין רכיבים המבקשים גישה למשאבים משותפים, ניהול signaling, תכנון interconnect, ניהול צריכת חשמל ואבטחה. הפרוטוקול AMBA כולל מספר מפרטים שונים שמותאמים לצרכים מגוונים של טרנזקציות וסוכנים במערכת, כולל AHB, APB, AXI, ACE ו-CHI. כל אחד מפרוטוקולים אלו מתמקד בהיבט מסוים של התקשורת בין רכיבי המערכת.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;זיכרון RAM מהיר כמו ליבות המעבד המודרניות יקר בהרבה לעומת זיכרון DRAM הקונבנציונלי. העלויות הגבוהות של זיכרון מהיר נוטות להיות מנוטרלות על ידי התקורות הכרוכות בניהול המשאבים. לכן, במקום להפוך את ה-SRAM למשאב שנשלט על ידי מערכת ההפעלה או המשתמש, הוא מנוהל ישירות על ידי המעבד, והשימוש בו שקוף למערכת.&lt;/p&gt;&#xA;&lt;p&gt;במקרה כזה, ה-SRAM משמש כזיכרון cache, כלומר, כמאגר זמני עבור נתונים מהזיכרון הראשי, אשר סביר להניח שיעשה בהם שימוש בקרוב על ידי המעבד. הדבר מתאפשר בזכות העובדה שהקוד והנתונים של תוכנה נוטים להפגין מקומיות זמנית ומרחבית.&lt;/p&gt;</description>
    </item>
    <item>
      <title>x86 Lock</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/x86-lock/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/x86-lock/</guid>
      <description>&lt;h2 id=&#34;lock-prefix&#34;&gt;lock prefix&lt;/h2&gt;&#xA;&lt;p&gt;ה-lock prefix הוא קידומת של של ה-opcode (הקידומת היא &lt;code&gt;0xF0&lt;/code&gt;) והוא מאפשר לבצע פעולות אטומיות.&lt;/p&gt;&#xA;&lt;p&gt;ה-lock prefix גורמת לאות &lt;code&gt;LOCK#&lt;/code&gt; של המעבד להישאר פעיל במהלך ביצוע ההוראה המצורפת אליה, מה שהופך את ההוראה לאטומית. בסביבה עם ריבוי מעבדים, האות &lt;code&gt;LOCK#&lt;/code&gt; מבטיח שהמעבד המחזיק באות יש שימוש בלעדי בכל זיכרון משותף בזמן שהאות פעיל.&lt;/p&gt;&#xA;&lt;p&gt;ניתן להוסיף את קידומת &lt;code&gt;LOCK&lt;/code&gt; רק לקבוצה מסוימת של הוראות, ורק במקרים שבהם אופרנד היעד של ההוראה הוא אופרנד זיכרון. הוראות מסוימות שניתן להוסיף להן את קידומת &lt;code&gt;LOCK&lt;/code&gt; כוללות:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimizations</title>
      <link>https://smichaelshal.github.io/he/posts/compiler/optimizations/</link>
      <pubDate>Sat, 24 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/compiler/optimizations/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;הקומפיילר יכול לשנות את הסדר של הפעולות של התוכנית, להוסיף ולבטל loads ו-stores ,לעשות ספקולציות של ערכים, ועוד אופטימיזציות יצרתיות בתנאי שזה לא משפיע על הפעולה הנראית לעין של התוכנית.&lt;/p&gt;&#xA;&lt;p&gt;לדוגמה זה יכול לבוא לידי ביטוי על ידי רצף של stores שיכול להשתנות, זה לא מפריע לרוב ב-thread יחיד אבל כשיש מספר thread-ים אז זה כבר בעייתי.&lt;/p&gt;&#xA;&lt;h2 id=&#34;אופטימיזציות-קומפיילר&#34;&gt;אופטימיזציות קומפיילר&lt;/h2&gt;&#xA;&lt;p&gt;בדומה לאופטימיזציות שנעשות ברמת ארכיטקטורת החומרה, גם אופטימיזציות קומפיילר נפוצות יכולות לשנות את האופן שבו פעולות זיכרון משותף מתבצעות, וכתוצאה מכך, להשפיע על ההתנהגות של תוכנות מקביליות. אופטימיזציות כגון הקצאת רגיסטרים, תנועת קוד (code motion), חיסול תת-ביטויים נפוצים, שינויי מבנה לולאות, וחסימת טרנספורמציות (blocking transformations), כולן משפיעות על סידור פעולות הזיכרון ואף עלולות לגרום לביטולן. ההשפעות של אופטימיזציות כאלה עלולות להיות קריטיות כאשר מקמפלים תוכנות מקביליות שמוגדרות באופן מפורש.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combined buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בגלל שלקריאה וכתיבה לזיכרון חיצוני עלולה להיות זמן השהייה ממושך, מעבדים יכולים לצמצם את מספר ההעברות על ידי מיזוג מספר כתיבות (stores) לטרנזקציה אחת גדולה יותר. על ידי כך, המעבד מבצע את הכתיבות כפעולה אחת מרוכזת, מה שמפחית את העומס על ה-bus ושיפור היעילות של הגישה לזיכרון החיצוני.&lt;/p&gt;&#xA;&lt;p&gt;שילוב כתיבה הוא אופטימיזציה שמטרתה לצמצם את כמות ההעברות בין ה-cache למכשירים, במיוחד במצבים שבהם עלויות ההעברה גבוהות משמעותית מהגישה המקומית ל-RAM. לדוגמה, בכרטיסים גרפיים, שעלויות ההעברה למכשירים גבוהות הרבה יותר. לכן, יש להימנע מהעברות מיותרות. אם יש צורך להעביר שורת cache שלמה רק בגלל שכתיבה אחת שונתה, זו פעולה בזבזנית, במיוחד אם הפעולה הבאה משנה מילה נוספת באותה השורה. בהתאם לכך, שילוב כתיבה אוסף מספר שינויים לפני שכותב את שורת ה-cache למכשיר. במצבים אידיאליים, כל מילה בשורת ה-cache משתנה אחת אחרי השנייה ורק לאחר שהמילה האחרונה השתנתה, שורת ה-cache נכתבת למכשיר.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoder</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/decoder/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/decoder/</guid>
      <description>&lt;p&gt;מעבדים מבצעים הוראות באמצעות טכניקת ה-pipeline, שבה כל הוראה עוברת סדרת שלבים: תחילה היא מפוענחת, לאחר מכן מתבצע הכנת הפרמטרים, ולבסוף ההוראה מבוצעת. כאשר ה-pipeline ארוך, זה אומר שאם מתרחשת תקלה ב-pipeline (כלומר, כאשר זרימת ההוראות עוצרת), לוקח זמן להחזיר אותו למצב של פעולה רגילה. תקלות ב-pipeline יכולות להתרחש כאשר קשה לחזות את מיקום ההוראה הבאה או כאשר לוקח זמן רב לטעון את ההוראה הבאה מהזיכרון.&lt;/p&gt;&#xA;&lt;p&gt;ב-pipeline, ה&amp;quot;טריק&amp;quot; הוא להתחיל לפענח את ההוראה הבאה עוד לפני שההוראה הנוכחית עזבה את המעבד, בדומה לפס ייצור. כך, מפענח הכתובות נשאר בתפקוד רציף ולא נותר ללא עבודה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fetch</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/fetch/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/fetch/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;מבוא&lt;/h1&gt;&#xA;&lt;h2 id=&#34;שליפה-מוקדמת&#34;&gt;שליפה מוקדמת&lt;/h2&gt;&#xA;&lt;p&gt;מטרת השליפה המוקדמת היא להפחית את זמן ההשהיה של גישה לזיכרון. למרות שה-pipeline של ההוראות ויכולת הביצוע מחוץ לסדר (out-of-order) של מעבדים מודרניים יכולים להפחית חלק מהשהיית הזיכרון, זה מוגבל בעיקר לגישות שהן cache hit. כדי לכסות את כל זמן האחזור של גישה לזיכרון הראשי, ה-pipeline היה צריך להיות ארוך מאוד, מה שלא פרקטי. חלק מהמעבדים שאינם תומכים בביצוע מחוץ לסדר מנסים לפצות על כך באמצעות הגדלת מספר הליבות, אך זה יעיל רק אם כל הקוד יכול לפעול במקביל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Invalidate queue</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בפרוטוקולי קוהרנטיות מסוג Invalidate קיימים מספר סוגי הודעות ובניהם הודעות Invalidate פשוטות:&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate:&#xA;הודעת invalidate כוללת את הכתובת הפיזית של שורת ה-cache שיש לבטל את תוקפה. כל מעבד אחר במערכת מחויב להסיר את הנתונים הרלוונטיים מה-cache שלו ולהגיב בהתאם.&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate Acknowledge:&#xA;כאשר מעבד מקבל הודעת invalidate, הוא חייב להשיב בהודעת invalidate acknowledge לאחר שהסיר את הנתונים שצוינו מה-cache שלו.&lt;/p&gt;&#xA;&lt;p&gt;במערכות מחשוב מתקדמות, קיימים מבנים פנימיים כמו ה-store buffer, שתפקידם לאגור באופן זמני את המידע המיועד לכתיבה בזיכרון הראשי. עם זאת, מגבלות בגודל ה-store buffer מחייבות את המעבד לנהל בקפידה את השימוש בו. כאשר המעבד מבצע רצף פעולות כתיבה (stores), במיוחד אם כל אחת מהן גורמת ל-cache miss, ה-store buffer עלול להתמלא במהירות. ברגע שה-buffer מתמלא, המעבד חייב להמתין לסיום תהליך ה-invalidations, שבמהלכו מבטלים שורות cache ישנות כדי לרוקן את ה-buffer ולאפשר המשך ביצוע. מצב זה עלול להתרחש גם לאחר הפעלת מחסום זיכרון, כאשר כל פעולות ה-store הבאות תלויות בהשלמת תהליך ה-invalidations, גם אם אין החמצת cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Line fill buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</guid>
      <description>&lt;p&gt;כשהנתונים שנכתבים לכתובת באזור זיכרון Write-Back ה-stores נמצאים ב-store buffer, הם נשארים שם עד שה-store מבצע פרישה. לאחר הפרישה, הנתונים נכתבים ל-L1 Data Cache אם השורה קיימת ויש לה הרשאת כתיבה. אם לא, ה-Line Fill Buffer (LFB) מוקצה לטיפול בכתיבה במקרה של store miss. ה-LFB מקבל בסופו של דבר את העותק העדכני של שורת ה-cache, כך שניתן להתקין אותה ב-L1 Data Cache ולבצע את הכתיבה של נתוני ה-store ל-cache. פרטים נוספים לגבי מיזוג, buffering, סדרי עדיפויות ו&amp;quot;קיצורי דרך&amp;quot; אינם תמיד ברורים, אך אחת מהפרשנויות היא ש-LFBs פועלים כ-buffers בגודל cache, שבהם מתמזגים נתוני ה-store לפני שליחתם ל-L1 Data Cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MOESI</title>
      <link>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/moesi/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/coherence-protocol/moesi/</guid>
      <description>&lt;p&gt;פרוטוקול MOESI הוא פרוטוקול קוהרנטיות cache ממשפחת פרוטוקולי MESI המבוסס Invalidate והוא נקרא על שם ה-stable state של ה-cache lines שהוא מאפשר. מטרתו היא לאפשר ניהול יעיל (יחסית) של ה-cache.&lt;/p&gt;&#xA;&lt;p&gt;הפרוטוקול משמש בעיקר ל-cache-ים עם גישות מורכבות יחסית כשצריך לנסות ליעל את הטרזקציות בצורה יעילה, למשל השימוש הנפוץ בו הוא ב-data cache, לעומת זאת ב-cache-ים אחרים כמו ה-instruction cache או ה-TLB משתמשים בפרוטוקולים יותר פשוטים.&lt;/p&gt;&#xA;&lt;h2 id=&#34;מצבי-cache-line&#34;&gt;מצבי Cache line&lt;/h2&gt;&#xA;&lt;h3 id=&#34;מצב-modified&#34;&gt;מצב Modified&lt;/h3&gt;&#xA;&lt;p&gt;ה-cache line הוא העותק היחיד שתקף, הוא בעל הרשאות לקריאה וכתיבה ויכול להיות שהמידע בו שונה מהזיכרון הראשי&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reorder buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;ה-reorder buffer הוא יחידת חומרה המשמשת באופן נרחב יחד עם אלגוריתם Tomasulo לתמיכה בביצוע פקודות לא מסודרות וספקולטיביות. הוא מבטיח שההוראות יתבצעו בסדר המתואם.&lt;/p&gt;&#xA;&lt;p&gt;ה-buffer מיושם כמערך מעגלי, המיועד לספק תור לסדר הוראות שנמצאות בעיבוד לפי FIFO. הוא מאפשר רישום של תוצאות מול ההוראות כאשר הן מסתיימות, גם אם הן בוצעו מחוץ לסדר.&lt;/p&gt;&#xA;&lt;p&gt;מעבדי x86 מודרניים מבצעים loads ספקולטיביות מוקדמות לפני טעינות אחרות, ולעיתים עלולים &amp;ldquo;להשמיד&amp;rdquo; ספקולציה שגויה של סדר הזיכרון אם הם מזהים שהעותק שלהם של שורת ה-cache לא נשאר תקף מאז שה-load התבצעה בפועל, בהתאם להתרות הארכיטקטוניות. במקרה כזה, הם משליכים את תוכן ה-reorder buffer כדי לחזור למצב עקבי ולהתחיל מחדש את הביצוע. זה קורה בדרך כלל כאשר ליבה אחרת משנה את שורת ה-cache, אך עשוי להתרחש גם אם load חזה בטעות שלא תדרוש טעינה מחדש של store. (כמובן, מעבדי x86 אמיתיים יכולים לסדר מחדש בחופשיות טעינות לפני stores.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uops</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/uops/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/uops/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים, micro-operations (המכונות גם micro-ops או μops, ובאופן היסטורי micro-actions) הן הוראות ברמה נמוכה המשמשות ליישום הוראות מכונה מורכבות בעיצובים מסוימים (לעיתים מכונות פקודות מאקרו בהקשר זה).&lt;/p&gt;&#xA;&lt;p&gt;בדרך כלל, micro-operations מבצעות פעולות בסיסיות על נתונים המאוחסנים ברגיסטר אחד או יותר, כמו העברת נתונים בין רגיסטרים או בין רגיסטרים לבין bus-ים חיצוניים של המעבד (CPU), וכן ביצוע פעולות אריתמטיות או לוגיות על הנתונים ברגיסטרים. במחזור fetch -&amp;gt; decode -&amp;gt; execute טיפוסי, כל שלב בהוראת מאקרו מתפרק במהלך הביצוע, כך שהמעבד קובע ומבצע סדרה של micro-operations. הביצוע של micro-operations מתבצע תחת שליטת יחידת הבקרה של המעבד, אשר מבצעת אופטימיזציות שונות כמו סידור מחדש, היתוך ואחסון ב-cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exclusive</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/exclusive/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/exclusive/</guid>
      <description>&lt;h2 id=&#34;load-lockstore-conditional-llsc&#34;&gt;Load Lock/Store Conditional (LL/SC)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;load-lockstore-conditional&#34;&gt;Load-Lock/Store-Conditional&lt;/h3&gt;&#xA;&lt;p&gt;ה-Load-Lock ו-Store-Conditional נקרא גם Load-Link/Store-Conditional הן צמד הוראות המשמשות ב-multithreading כדי להשיג סנכרון בין thread-ים.&lt;/p&gt;&#xA;&lt;p&gt;ההוראה Load-Lock (או בקיצור LL) משמשת לקרוא את הערך הנוכחי במיקום זיכרון,  ההוראה רושמת באופן פנימי (למשל ב-arm המידע נשמר ב- exclusive monitors) את מיקום הזיכרון לצורך גישה בלעדית, בעוד שההוראה Store-Conditional (או בקיצור SC) נועדה לשמור ערך חדש באותו מיקום זיכרון, אך רק אם לא התרחשו שינויים באותו מיקום זיכרון מאז ההוראת ה-LL התואמת הקודמת.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Atomic</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/atomic/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/atomic/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;כאשר מספר thread-ים מנסים לשנות בו-זמנית את אותו מיקום בזיכרון, המעבדים אינם מבטיחים תוצאה ספציפית כלשהי כתוצאה מהפעולה.&lt;/p&gt;&#xA;&lt;p&gt;כשאנחנו אומרים שעדכון מסוג RMW, כמו למשל &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt;, הוא אטומי, הכוונה היא לכך שמיקום הזיכרון (במקרה הזה, &lt;code&gt;x&lt;/code&gt;) לא ישתנה בין שלבי הקריאה והכתיבה שמרכיבים את הפעולה האטומית. במילים אחרות, אם שני מעבדים מבצעים את &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt; במקביל, יש לוודא שהערך הסופי של &lt;code&gt;x&lt;/code&gt; יהיה הערך ההתחלתי בתוספת 2.&#xA;אין מצב שבו ניתן יהיה לקבל רצף אירועים כזה:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
