<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>X86 on Michael Shalitin</title>
    <link>https://smichaelshal.github.io/he/tags/x86/</link>
    <description>Recent content in X86 on Michael Shalitin</description>
    <generator>Hugo</generator>
    <language>he</language>
    <lastBuildDate>Sat, 02 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://smichaelshal.github.io/he/tags/x86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Acquire Release</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/acquire-release/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;ההוראות מסוג load-acquire ו-store-release, כוללות מחסומים מובנים חד-כיווניים, המאפשרים דרישות סדר חלשות ממחסומים כלליים. הן משפיעות על הסדר של גישה לזיכרון מפורש שצוינו שנמצא בכל צד של הוראת מחסום הזיכרון. אופי זה מאפשר ביצועים משופרים בזכות אופטימיזציות מיקרו-ארכיטקטוניות ומצמצם את השפעת הביצועים לעומת מחסום זיכרון כללי.&lt;/p&gt;&#xA;&lt;p&gt;כאשר הסדר הנדרש נתמך על ידי load-acquire או store-release, מומלץ להשתמש בהן במקום במחסום כללי כדי לשפר את היעילות.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Models</title>
      <link>https://smichaelshal.github.io/he/posts/models/models/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/models/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;מחשבים, בהיותם אוטומטים דטרמיניסטיים, בדרך כלל יניבו התנהגות צפויה ואחידה, ולכן רוב האנשים יחשבו שגזירת התוצאה היא אחת בלבד. עבור מערכות חד-מעבדים, רוב הזמן הם יהיו נכונים בהנחה הזו. עם זאת, במערכות מרובות מעבדים, התמונה משתנה, והן יכולות להוביל למגוון רחב הרבה יותר של התנהגויות. זאת בשל שינויים עדינים בתזמון היחסי של המעבדים השונים במערכת, כמו גם השפעת האותות המועברים ביניהם, ה-cache-ים והזיכרון הראשי.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ordering</title>
      <link>https://smichaelshal.github.io/he/posts/models/ordering/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/ordering/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים מודרניים ישנן הוראות רבות שלא ניתן להשלים מיידית, מאחר והן דורשות זמן לביצוע (מספר מחזורי שעון).&lt;/p&gt;&#xA;&lt;p&gt;במצב זה, ביצוע in-order משמעו שהמעבד ימתין בכל פעם שהוראה דורשת נתונים חסרים או שהיא אורכת מספר מחזורים לביצוע, מה שמוביל לעיכובים (stalls) בתהליך העיבוד.&lt;/p&gt;&#xA;&lt;p&gt;לעומת זאת, בביצוע out-of-order, נעשה שימוש בטכניקות מתקדמות למעקב אחר נתונים. כאשר הוראה מסוימת אינה יכולה להתבצע בשל חוסר בנתונים, המעבד לא נכנס למצב של stall, אלא מריץ הוראות אחרות, כל עוד אין תלות ישירה בינן לבין ההוראות שטרם הושלמו. כך המעבד מנצל ביעילות את זמנו הפנוי וממשיך לעבד הוראות שאינן דורשות המתנה לנתונים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>mb</title>
      <link>https://smichaelshal.github.io/he/posts/barriers/mb/</link>
      <pubDate>Sat, 12 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/barriers/mb/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;מחסום זיכרון הוא הוראה המיועדת לאכוף מגבלות סדר על פעולות זיכרון המבוצעות לפני ואחרי הוראת המחסום. זה מתבטא בכך שפעולות זיכרון שביצוען סודר לפני המחסום יבוצעו לפני כל פעולות זיכרון שניתן להן לאחר המחסום.&lt;/p&gt;&#xA;&lt;p&gt;חשיבות האכיפה שהמחסומים מספקים נובעת מהעובדה שמעבדים והתקנים אחרים במערכת עשויים לנצל מגוון טכניקות לשיפור ביצועים, כמו שינוי סדר ההוראות, דחייה ושילוב של פעולות זיכרון, ביצוע loads ספקולטיביות, חיזוי ספקולטיבי של branch-ים ושימוש בסוגים שונים של cache. מחסומי זיכרון נועדו לעקוף או לדכא את הטכניקות הללו או את השפעותיהם, כך שהקוד יכול לשלוט בצורה צפויה באינטראקציות בין מספר מעבדים או בין מעבד למכשירים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Speculation</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/speculation/</guid>
      <description>&lt;h1 id=&#34;ספקולציות&#34;&gt;&#xA;  ספקולציות&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%a1%d7%a4%d7%a7%d7%95%d7%9c%d7%a6%d7%99%d7%95%d7%aa&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;ביצוע ספקולטיבי הוא שיטת אופטימיזציה במערכות מחשב, שבה מבוצעות משימות מראש, לפני שנודע בוודאות אם הן נדרשות. המטרה היא לחסוך זמן ולמנוע עיכובים בביצוע העבודה לאחר שמתברר שהיא נדרשת. אם בסופו של דבר מתברר שהמשימה לא הייתה הכרחית, המערכת מבטלת את רוב השינויים שבוצעו ומתעלמת מתוצאות הביצוע.&lt;/p&gt;&#xA;&lt;p&gt;מטרת הביצוע הספקולטיבי היא להגדיל את ניצול המשאבים במערכת ולהפחית עיכובים. השיטה משמשת בתחומים רבים, כמו חיזוי נתיבי branch במעבדים עם pipeline, חיזוי ערכי נתונים לניצול מקומיות ערכית, ושליפת נתונים מראש מהזיכרון.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Register renaming</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/register-renaming/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/register-renaming/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;בארכיטקטורת מחשבים, Register Renaming הוא טכניקה שמבצעת הפרדה בין רגיסטרים לוגיים לרגיסטרים פיזיים. כל רגיסטר לוגי מקושר לקבוצה של רגיסטרים פיזיים, וכאשר הוראת שפת מכונה מתייחסת לרגיסטר לוגי, המעבד ממפה אותו לרגיסטר פיזי ספציפי במהלך הביצוע. הרגיסטרים הפיזיים אינם נגישים ישירות, וניתן לגשת אליהם רק דרך השמות הקנוניים של הרגיסטרים הלוגיים.&lt;/p&gt;&#xA;&lt;p&gt;טכניקה זו מאפשרת להתגבר על תלות כוזבת בנתונים הנובעת משימוש חוזר ברגיסטרים על ידי הוראות עוקבות שאין ביניהן תלות אמיתית. ביטול התלות הכוזבת מגביר את המקבילות ברמת ההוראה בזרם הפקודות, מה שמאפשר לנצל טכניקות כמו ביצוע על-סקלרי וביצוע מחוץ לסדר לשיפור הביצועים.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pipeline &amp; Hazard</title>
      <link>https://smichaelshal.github.io/he/posts/optimization-techniques/pipeline--hazard/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/optimization-techniques/pipeline--hazard/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;טכניקה נפוצה במעבדים מודרנים היא pipeline, הטכניקה מאפשרת הרצה של הוראות לא תלויות בו זמנית (concurrency) והיא מאפשרת שיפור ביצועים של המעבד.&lt;/p&gt;&#xA;&lt;p&gt;הרעיון ב-pipeline הוא שכל הוראה בודדת מורכבת מכמה פעולות שניתן להפריד, ולכל סוג של פעולה כזאת יכול להיות רכיב אחר שמטפל בה, וככה ניתן להתחיל את ההוראה הבאה לביצוע עוד לפני שההוראה הקודמת הסתיימה.&lt;/p&gt;&#xA;&lt;p&gt;הטכניקה מזכירה את שיטת פס ייצור, בפס ייצור אין מכונה או אדם בודד שמייצרים את המוצר מהתחלה ועד הסוף, כל רכיב אחרי רק על פעולה אחת בודדת ופשוטה יחסית וכל הפעולות האלו מתרחשות בו זמנית.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache maintenance</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache-maintenance/</guid>
      <description>&lt;h2 id=&#34;תחזוקת-cache-בתוכנה&#34;&gt;&#xA;  תחזוקת cache בתוכנה&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%aa%d7%97%d7%96%d7%95%d7%a7%d7%aa-cache-%d7%91%d7%aa%d7%95%d7%9b%d7%a0%d7%94&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;לעיתים יש צורך בתוכנה לבצע פעולות ניקוי או ביטול של ה-cache. פעולות אלו נדרשות כאשר תוכן הזיכרון החיצוני השתנה, ויש צורך להבטיח שה-cache אינו מכיל נתונים מיושנים. פעולות אלו יכולות להיות נדרשות גם לאחר שינויים הקשורים ל-MMU כמו שינוי הרשאות גישה, מדיניות cache, מיפוי כתובות וירטואליות לכתובת פיזית, או כאשר ה-I-caches ו-D-caches חייבים להיות מסונכרנים לקוד שנוצר באופן דינמי, כגון ב-JIT-compilers וטועני ספריות דינמיות.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache</title>
      <link>https://smichaelshal.github.io/he/posts/cache/cache/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/cache/cache/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;זיכרון RAM מהיר כמו ליבות המעבד המודרניות יקר בהרבה לעומת זיכרון DRAM הקונבנציונלי. העלויות הגבוהות של זיכרון מהיר נוטות להיות מנוטרלות על ידי התקורות הכרוכות בניהול המשאבים. לכן, במקום להפוך את ה-SRAM למשאב שנשלט על ידי מערכת ההפעלה או המשתמש, הוא מנוהל ישירות על ידי המעבד, והשימוש בו שקוף למערכת.&lt;/p&gt;&#xA;&lt;p&gt;במקרה כזה, ה-SRAM משמש כזיכרון cache, כלומר, כמאגר זמני עבור נתונים מהזיכרון הראשי, אשר סביר להניח שיעשה בהם שימוש בקרוב על ידי המעבד. הדבר מתאפשר בזכות העובדה שהקוד והנתונים של תוכנה נוטים להפגין מקומיות זמנית ומרחבית.&lt;/p&gt;</description>
    </item>
    <item>
      <title>x86 Lock</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/x86-lock/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/x86-lock/</guid>
      <description>&lt;h2 id=&#34;lock-prefix&#34;&gt;&#xA;  lock prefix&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#lock-prefix&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;ה-lock prefix הוא קידומת של של ה-opcode (הקידומת היא &lt;code&gt;0xF0&lt;/code&gt;) והוא מאפשר לבצע פעולות אטומיות.&lt;/p&gt;&#xA;&lt;p&gt;ה-lock prefix גורמת לאות &lt;code&gt;LOCK#&lt;/code&gt; של המעבד להישאר פעיל במהלך ביצוע ההוראה המצורפת אליה, מה שהופך את ההוראה לאטומית. בסביבה עם ריבוי מעבדים, האות &lt;code&gt;LOCK#&lt;/code&gt; מבטיח שהמעבד המחזיק באות יש שימוש בלעדי בכל זיכרון משותף בזמן שהאות פעיל.&lt;/p&gt;&#xA;&lt;p&gt;ניתן להוסיף את קידומת &lt;code&gt;LOCK&lt;/code&gt; רק לקבוצה מסוימת של הוראות, ורק במקרים שבהם אופרנד היעד של ההוראה הוא אופרנד זיכרון. הוראות מסוימות שניתן להוסיף להן את קידומת &lt;code&gt;LOCK&lt;/code&gt; כוללות:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoder</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/decoder/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/decoder/</guid>
      <description>&lt;p&gt;מעבדים מבצעים הוראות באמצעות טכניקת ה-pipeline, שבה כל הוראה עוברת סדרת שלבים: תחילה היא מפוענחת, לאחר מכן מתבצע הכנת הפרמטרים, ולבסוף ההוראה מבוצעת. כאשר ה-pipeline ארוך, זה אומר שאם מתרחשת תקלה ב-pipeline (כלומר, כאשר זרימת ההוראות עוצרת), לוקח זמן להחזיר אותו למצב של פעולה רגילה. תקלות ב-pipeline יכולות להתרחש כאשר קשה לחזות את מיקום ההוראה הבאה או כאשר לוקח זמן רב לטעון את ההוראה הבאה מהזיכרון.&lt;/p&gt;&#xA;&lt;p&gt;ב-pipeline, ה&amp;quot;טריק&amp;quot; הוא להתחיל לפענח את ההוראה הבאה עוד לפני שההוראה הנוכחית עזבה את המעבד, בדומה לפס ייצור. כך, מפענח הכתובות נשאר בתפקוד רציף ולא נותר ללא עבודה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fetch</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/fetch/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/fetch/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;שליפה-מוקדמת&#34;&gt;&#xA;  שליפה מוקדמת&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%a9%d7%9c%d7%99%d7%a4%d7%94-%d7%9e%d7%95%d7%a7%d7%93%d7%9e%d7%aa&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;מטרת השליפה המוקדמת היא להפחית את זמן ההשהיה של גישה לזיכרון. למרות שה-pipeline של ההוראות ויכולת הביצוע מחוץ לסדר (out-of-order) של מעבדים מודרניים יכולים להפחית חלק מהשהיית הזיכרון, זה מוגבל בעיקר לגישות שהן cache hit. כדי לכסות את כל זמן האחזור של גישה לזיכרון הראשי, ה-pipeline היה צריך להיות ארוך מאוד, מה שלא פרקטי. חלק מהמעבדים שאינם תומכים בביצוע מחוץ לסדר מנסים לפצות על כך באמצעות הגדלת מספר הליבות, אך זה יעיל רק אם כל הקוד יכול לפעול במקביל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reorder buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;ה-reorder buffer הוא יחידת חומרה המשמשת באופן נרחב יחד עם אלגוריתם Tomasulo לתמיכה בביצוע פקודות לא מסודרות וספקולטיביות. הוא מבטיח שההוראות יתבצעו בסדר המתואם.&lt;/p&gt;&#xA;&lt;p&gt;ה-buffer מיושם כמערך מעגלי, המיועד לספק תור לסדר הוראות שנמצאות בעיבוד לפי FIFO. הוא מאפשר רישום של תוצאות מול ההוראות כאשר הן מסתיימות, גם אם הן בוצעו מחוץ לסדר.&lt;/p&gt;&#xA;&lt;p&gt;מעבדי x86 מודרניים מבצעים loads ספקולטיביות מוקדמות לפני טעינות אחרות, ולעיתים עלולים &amp;ldquo;להשמיד&amp;rdquo; ספקולציה שגויה של סדר הזיכרון אם הם מזהים שהעותק שלהם של שורת ה-cache לא נשאר תקף מאז שה-load התבצעה בפועל, בהתאם להתרות הארכיטקטוניות. במקרה כזה, הם משליכים את תוכן ה-reorder buffer כדי לחזור למצב עקבי ולהתחיל מחדש את הביצוע. זה קורה בדרך כלל כאשר ליבה אחרת משנה את שורת ה-cache, אך עשוי להתרחש גם אם load חזה בטעות שלא תדרוש טעינה מחדש של store. (כמובן, מעבדי x86 אמיתיים יכולים לסדר מחדש בחופשיות טעינות לפני stores.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uops</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/uops/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/uops/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים, micro-operations (המכונות גם micro-ops או μops, ובאופן היסטורי micro-actions) הן הוראות ברמה נמוכה המשמשות ליישום הוראות מכונה מורכבות בעיצובים מסוימים (לעיתים מכונות פקודות מאקרו בהקשר זה).&lt;/p&gt;&#xA;&lt;p&gt;בדרך כלל, micro-operations מבצעות פעולות בסיסיות על נתונים המאוחסנים ברגיסטר אחד או יותר, כמו העברת נתונים בין רגיסטרים או בין רגיסטרים לבין bus-ים חיצוניים של המעבד (CPU), וכן ביצוע פעולות אריתמטיות או לוגיות על הנתונים ברגיסטרים. במחזור fetch -&amp;gt; decode -&amp;gt; execute טיפוסי, כל שלב בהוראת מאקרו מתפרק במהלך הביצוע, כך שהמעבד קובע ומבצע סדרה של micro-operations. הביצוע של micro-operations מתבצע תחת שליטת יחידת הבקרה של המעבד, אשר מבצעת אופטימיזציות שונות כמו סידור מחדש, היתוך ואחסון ב-cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Atomic</title>
      <link>https://smichaelshal.github.io/he/posts/atomic/atomic/</link>
      <pubDate>Sat, 10 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/atomic/atomic/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;כאשר מספר thread-ים מנסים לשנות בו-זמנית את אותו מיקום בזיכרון, המעבדים אינם מבטיחים תוצאה ספציפית כלשהי כתוצאה מהפעולה.&lt;/p&gt;&#xA;&lt;p&gt;כשאנחנו אומרים שעדכון מסוג RMW, כמו למשל &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt;, הוא אטומי, הכוונה היא לכך שמיקום הזיכרון (במקרה הזה, &lt;code&gt;x&lt;/code&gt;) לא ישתנה בין שלבי הקריאה והכתיבה שמרכיבים את הפעולה האטומית. במילים אחרות, אם שני מעבדים מבצעים את &lt;code&gt;atomic_inc(&amp;amp;x)&lt;/code&gt; במקביל, יש לוודא שהערך הסופי של &lt;code&gt;x&lt;/code&gt; יהיה הערך ההתחלתי בתוספת 2.&#xA;אין מצב שבו ניתן יהיה לקבל רצף אירועים כזה:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
