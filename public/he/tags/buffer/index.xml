<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Buffer on Michael Shalitin</title>
    <link>https://smichaelshal.github.io/he/tags/buffer/</link>
    <description>Recent content in Buffer on Michael Shalitin</description>
    <generator>Hugo</generator>
    <language>he</language>
    <lastBuildDate>Thu, 12 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://smichaelshal.github.io/he/tags/buffer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LKMM Code Examples</title>
      <link>https://smichaelshal.github.io/he/posts/models/lkmm-code-examples/</link>
      <pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/models/lkmm-code-examples/</guid>
      <description>&lt;h2 id=&#34;שימוש-במחסומי-זיכרון-עם-buffer-ים-מעגליים&#34;&gt;&#xA;  שימוש במחסומי זיכרון עם buffer-ים מעגליים&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%a9%d7%99%d7%9e%d7%95%d7%a9-%d7%91%d7%9e%d7%97%d7%a1%d7%95%d7%9e%d7%99-%d7%96%d7%99%d7%9b%d7%a8%d7%95%d7%9f-%d7%a2%d7%9d-buffer-%d7%99%d7%9d-%d7%9e%d7%a2%d7%92%d7%9c%d7%99%d7%99%d7%9d&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;שימוש במחסומי זיכרון בשילוב עם buffer-ים מעגליים מאפשר התמודדות עם בעיות סינכרון בצורה יעילה יותר, תוך הימנעות מהצורך במנגנונים כבדים כמו:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;המנעות מנעילה:&lt;/strong&gt; במקום להשתמש במנעול ששולט על שני הקצוות של ה-buffer (הקצה של הכתיבה והקצה של הקריאה), ניתן לאפשר גישה בו-זמנית לשני הצדדים. כך היצרן יכול להכניס נתונים ל-buffer בו זמנית עם הצרכן שמוציא נתונים ממנו, מבלי להשתמש במנעול.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Store buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;המעבדים היום הרבה יותר מהירים מהזיכרון הראשי ולכן כל גישה לזיכרון יכולה לגרום לעיכוב משמעותי בביצועי המעבד ולכן מעבדים מנסים לצמצם ככל הניתן את העיכוב הזה, ולכן פותחו טכניקות שמנסות לנתק כמה שניתן את ביצועי המעבד מהזיכרון עצמו, כמו cache-ים וכל מיני סוגי buffer-ים יעודיים.&lt;/p&gt;&#xA;&lt;p&gt;אחד ה-buffer-ים המרכזיים הוא ה-store buffer (ידוע גם כ-write buffer) והמטרה שלו היא לנתק את ביצוע הכתיבה של המעבד.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combined buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;בגלל שלקריאה וכתיבה לזיכרון חיצוני עלולה להיות זמן השהייה ממושך, מעבדים יכולים לצמצם את מספר ההעברות על ידי מיזוג מספר כתיבות (stores) לטרנזקציה אחת גדולה יותר. על ידי כך, המעבד מבצע את הכתיבות כפעולה אחת מרוכזת, מה שמפחית את העומס על ה-bus ושיפור היעילות של הגישה לזיכרון החיצוני.&lt;/p&gt;&#xA;&lt;p&gt;שילוב כתיבה הוא אופטימיזציה שמטרתה לצמצם את כמות ההעברות בין ה-cache למכשירים, במיוחד במצבים שבהם עלויות ההעברה גבוהות משמעותית מהגישה המקומית ל-RAM. לדוגמה, בכרטיסים גרפיים, שעלויות ההעברה למכשירים גבוהות הרבה יותר. לכן, יש להימנע מהעברות מיותרות. אם יש צורך להעביר שורת cache שלמה רק בגלל שכתיבה אחת שונתה, זו פעולה בזבזנית, במיוחד אם הפעולה הבאה משנה מילה נוספת באותה השורה. בהתאם לכך, שילוב כתיבה אוסף מספר שינויים לפני שכותב את שורת ה-cache למכשיר. במצבים אידיאליים, כל מילה בשורת ה-cache משתנה אחת אחרי השנייה ורק לאחר שהמילה האחרונה השתנתה, שורת ה-cache נכתבת למכשיר.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoder</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/decoder/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/decoder/</guid>
      <description>&lt;p&gt;מעבדים מבצעים הוראות באמצעות טכניקת ה-pipeline, שבה כל הוראה עוברת סדרת שלבים: תחילה היא מפוענחת, לאחר מכן מתבצע הכנת הפרמטרים, ולבסוף ההוראה מבוצעת. כאשר ה-pipeline ארוך, זה אומר שאם מתרחשת תקלה ב-pipeline (כלומר, כאשר זרימת ההוראות עוצרת), לוקח זמן להחזיר אותו למצב של פעולה רגילה. תקלות ב-pipeline יכולות להתרחש כאשר קשה לחזות את מיקום ההוראה הבאה או כאשר לוקח זמן רב לטעון את ההוראה הבאה מהזיכרון.&lt;/p&gt;&#xA;&lt;p&gt;ב-pipeline, ה&amp;quot;טריק&amp;quot; הוא להתחיל לפענח את ההוראה הבאה עוד לפני שההוראה הנוכחית עזבה את המעבד, בדומה לפס ייצור. כך, מפענח הכתובות נשאר בתפקוד רציף ולא נותר ללא עבודה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fetch</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/fetch/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/fetch/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;שליפה-מוקדמת&#34;&gt;&#xA;  שליפה מוקדמת&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%a9%d7%9c%d7%99%d7%a4%d7%94-%d7%9e%d7%95%d7%a7%d7%93%d7%9e%d7%aa&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;מטרת השליפה המוקדמת היא להפחית את זמן ההשהיה של גישה לזיכרון. למרות שה-pipeline של ההוראות ויכולת הביצוע מחוץ לסדר (out-of-order) של מעבדים מודרניים יכולים להפחית חלק מהשהיית הזיכרון, זה מוגבל בעיקר לגישות שהן cache hit. כדי לכסות את כל זמן האחזור של גישה לזיכרון הראשי, ה-pipeline היה צריך להיות ארוך מאוד, מה שלא פרקטי. חלק מהמעבדים שאינם תומכים בביצוע מחוץ לסדר מנסים לפצות על כך באמצעות הגדלת מספר הליבות, אך זה יעיל רק אם כל הקוד יכול לפעול במקביל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Invalidate queue</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;בפרוטוקולי קוהרנטיות מסוג Invalidate קיימים מספר סוגי הודעות ובניהם הודעות Invalidate פשוטות:&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate:&#xA;הודעת invalidate כוללת את הכתובת הפיזית של שורת ה-cache שיש לבטל את תוקפה. כל מעבד אחר במערכת מחויב להסיר את הנתונים הרלוונטיים מה-cache שלו ולהגיב בהתאם.&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate Acknowledge:&#xA;כאשר מעבד מקבל הודעת invalidate, הוא חייב להשיב בהודעת invalidate acknowledge לאחר שהסיר את הנתונים שצוינו מה-cache שלו.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Line fill buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</guid>
      <description>&lt;p&gt;כשהנתונים שנכתבים לכתובת באזור זיכרון Write-Back ה-stores נמצאים ב-store buffer, הם נשארים שם עד שה-store מבצע פרישה. לאחר הפרישה, הנתונים נכתבים ל-L1 Data Cache אם השורה קיימת ויש לה הרשאת כתיבה. אם לא, ה-Line Fill Buffer (LFB) מוקצה לטיפול בכתיבה במקרה של store miss. ה-LFB מקבל בסופו של דבר את העותק העדכני של שורת ה-cache, כך שניתן להתקין אותה ב-L1 Data Cache ולבצע את הכתיבה של נתוני ה-store ל-cache. פרטים נוספים לגבי מיזוג, buffering, סדרי עדיפויות ו&amp;quot;קיצורי דרך&amp;quot; אינם תמיד ברורים, אך אחת מהפרשנויות היא ש-LFBs פועלים כ-buffers בגודל cache, שבהם מתמזגים נתוני ה-store לפני שליחתם ל-L1 Data Cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reorder buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;ה-reorder buffer הוא יחידת חומרה המשמשת באופן נרחב יחד עם אלגוריתם Tomasulo לתמיכה בביצוע פקודות לא מסודרות וספקולטיביות. הוא מבטיח שההוראות יתבצעו בסדר המתואם.&lt;/p&gt;&#xA;&lt;p&gt;ה-buffer מיושם כמערך מעגלי, המיועד לספק תור לסדר הוראות שנמצאות בעיבוד לפי FIFO. הוא מאפשר רישום של תוצאות מול ההוראות כאשר הן מסתיימות, גם אם הן בוצעו מחוץ לסדר.&lt;/p&gt;&#xA;&lt;p&gt;מעבדי x86 מודרניים מבצעים loads ספקולטיביות מוקדמות לפני טעינות אחרות, ולעיתים עלולים &amp;ldquo;להשמיד&amp;rdquo; ספקולציה שגויה של סדר הזיכרון אם הם מזהים שהעותק שלהם של שורת ה-cache לא נשאר תקף מאז שה-load התבצעה בפועל, בהתאם להתרות הארכיטקטוניות. במקרה כזה, הם משליכים את תוכן ה-reorder buffer כדי לחזור למצב עקבי ולהתחיל מחדש את הביצוע. זה קורה בדרך כלל כאשר ליבה אחרת משנה את שורת ה-cache, אך עשוי להתרחש גם אם load חזה בטעות שלא תדרוש טעינה מחדש של store. (כמובן, מעבדי x86 אמיתיים יכולים לסדר מחדש בחופשיות טעינות לפני stores.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uops</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/uops/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/uops/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;&#xA;  מבוא&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%d7%9e%d7%91%d7%95%d7%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים, micro-operations (המכונות גם micro-ops או μops, ובאופן היסטורי micro-actions) הן הוראות ברמה נמוכה המשמשות ליישום הוראות מכונה מורכבות בעיצובים מסוימים (לעיתים מכונות פקודות מאקרו בהקשר זה).&lt;/p&gt;&#xA;&lt;p&gt;בדרך כלל, micro-operations מבצעות פעולות בסיסיות על נתונים המאוחסנים ברגיסטר אחד או יותר, כמו העברת נתונים בין רגיסטרים או בין רגיסטרים לבין bus-ים חיצוניים של המעבד (CPU), וכן ביצוע פעולות אריתמטיות או לוגיות על הנתונים ברגיסטרים. במחזור fetch -&amp;gt; decode -&amp;gt; execute טיפוסי, כל שלב בהוראת מאקרו מתפרק במהלך הביצוע, כך שהמעבד קובע ומבצע סדרה של micro-operations. הביצוע של micro-operations מתבצע תחת שליטת יחידת הבקרה של המעבד, אשר מבצעת אופטימיזציות שונות כמו סידור מחדש, היתוך ואחסון ב-cache.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
