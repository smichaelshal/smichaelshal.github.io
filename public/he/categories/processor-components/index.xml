<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Processor-Components on Michael Shalitin</title>
    <link>https://smichaelshal.github.io/he/categories/processor-components/</link>
    <description>Recent content in Processor-Components on Michael Shalitin</description>
    <generator>Hugo</generator>
    <language>he</language>
    <lastBuildDate>Sat, 05 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://smichaelshal.github.io/he/categories/processor-components/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Store buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/store-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;המעבדים היום הרבה יותר מהירים מהזיכרון הראשי ולכן כל גישה לזיכרון יכולה לגרום לעיכוב משמעותי בביצועי המעבד ולכן מעבדים מנסים לצמצם ככל הניתן את העיכוב הזה, ולכן פותחו טכניקות שמנסות לנתק כמה שניתן את ביצועי המעבד מהזיכרון עצמו, כמו cache-ים וכל מיני סוגי buffer-ים יעודיים.&lt;/p&gt;&#xA;&lt;p&gt;אחד ה-buffer-ים המרכזיים הוא ה-store buffer (ידוע גם כ-write buffer) והמטרה שלו היא לנתק את ביצוע הכתיבה של המעבד.&lt;/p&gt;&#xA;&lt;p&gt;ה-store buffer מאפשר למעבד לשגר את הוראת הכתיבה ואז הוא יכול &amp;ldquo;לשכוח&amp;rdquo; מהכתיבה וכל האחריות של ביצוע הכתיבה וכל מה שכרוך בה עוברת ל-store buffer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combined buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/combined-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בגלל שלקריאה וכתיבה לזיכרון חיצוני עלולה להיות זמן השהייה ממושך, מעבדים יכולים לצמצם את מספר ההעברות על ידי מיזוג מספר כתיבות (stores) לטרנזקציה אחת גדולה יותר. על ידי כך, המעבד מבצע את הכתיבות כפעולה אחת מרוכזת, מה שמפחית את העומס על ה-bus ושיפור היעילות של הגישה לזיכרון החיצוני.&lt;/p&gt;&#xA;&lt;p&gt;שילוב כתיבה הוא אופטימיזציה שמטרתה לצמצם את כמות ההעברות בין ה-cache למכשירים, במיוחד במצבים שבהם עלויות ההעברה גבוהות משמעותית מהגישה המקומית ל-RAM. לדוגמה, בכרטיסים גרפיים, שעלויות ההעברה למכשירים גבוהות הרבה יותר. לכן, יש להימנע מהעברות מיותרות. אם יש צורך להעביר שורת cache שלמה רק בגלל שכתיבה אחת שונתה, זו פעולה בזבזנית, במיוחד אם הפעולה הבאה משנה מילה נוספת באותה השורה. בהתאם לכך, שילוב כתיבה אוסף מספר שינויים לפני שכותב את שורת ה-cache למכשיר. במצבים אידיאליים, כל מילה בשורת ה-cache משתנה אחת אחרי השנייה ורק לאחר שהמילה האחרונה השתנתה, שורת ה-cache נכתבת למכשיר.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoder</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/decoder/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/decoder/</guid>
      <description>&lt;p&gt;מעבדים מבצעים הוראות באמצעות טכניקת ה-pipeline, שבה כל הוראה עוברת סדרת שלבים: תחילה היא מפוענחת, לאחר מכן מתבצע הכנת הפרמטרים, ולבסוף ההוראה מבוצעת. כאשר ה-pipeline ארוך, זה אומר שאם מתרחשת תקלה ב-pipeline (כלומר, כאשר זרימת ההוראות עוצרת), לוקח זמן להחזיר אותו למצב של פעולה רגילה. תקלות ב-pipeline יכולות להתרחש כאשר קשה לחזות את מיקום ההוראה הבאה או כאשר לוקח זמן רב לטעון את ההוראה הבאה מהזיכרון.&lt;/p&gt;&#xA;&lt;p&gt;ב-pipeline, ה&amp;quot;טריק&amp;quot; הוא להתחיל לפענח את ההוראה הבאה עוד לפני שההוראה הנוכחית עזבה את המעבד, בדומה לפס ייצור. כך, מפענח הכתובות נשאר בתפקוד רציף ולא נותר ללא עבודה.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fetch</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/fetch/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/fetch/</guid>
      <description>&lt;h1 id=&#34;מבוא&#34;&gt;מבוא&lt;/h1&gt;&#xA;&lt;h2 id=&#34;שליפה-מוקדמת&#34;&gt;שליפה מוקדמת&lt;/h2&gt;&#xA;&lt;p&gt;מטרת השליפה המוקדמת היא להפחית את זמן ההשהיה של גישה לזיכרון. למרות שה-pipeline של ההוראות ויכולת הביצוע מחוץ לסדר (out-of-order) של מעבדים מודרניים יכולים להפחית חלק מהשהיית הזיכרון, זה מוגבל בעיקר לגישות שהן cache hit. כדי לכסות את כל זמן האחזור של גישה לזיכרון הראשי, ה-pipeline היה צריך להיות ארוך מאוד, מה שלא פרקטי. חלק מהמעבדים שאינם תומכים בביצוע מחוץ לסדר מנסים לפצות על כך באמצעות הגדלת מספר הליבות, אך זה יעיל רק אם כל הקוד יכול לפעול במקביל.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Invalidate queue</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/invalidate-queue/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;בפרוטוקולי קוהרנטיות מסוג Invalidate קיימים מספר סוגי הודעות ובניהם הודעות Invalidate פשוטות:&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate:&#xA;הודעת invalidate כוללת את הכתובת הפיזית של שורת ה-cache שיש לבטל את תוקפה. כל מעבד אחר במערכת מחויב להסיר את הנתונים הרלוונטיים מה-cache שלו ולהגיב בהתאם.&lt;/p&gt;&#xA;&lt;p&gt;הודעות Invalidate Acknowledge:&#xA;כאשר מעבד מקבל הודעת invalidate, הוא חייב להשיב בהודעת invalidate acknowledge לאחר שהסיר את הנתונים שצוינו מה-cache שלו.&lt;/p&gt;&#xA;&lt;p&gt;במערכות מחשוב מתקדמות, קיימים מבנים פנימיים כמו ה-store buffer, שתפקידם לאגור באופן זמני את המידע המיועד לכתיבה בזיכרון הראשי. עם זאת, מגבלות בגודל ה-store buffer מחייבות את המעבד לנהל בקפידה את השימוש בו. כאשר המעבד מבצע רצף פעולות כתיבה (stores), במיוחד אם כל אחת מהן גורמת ל-cache miss, ה-store buffer עלול להתמלא במהירות. ברגע שה-buffer מתמלא, המעבד חייב להמתין לסיום תהליך ה-invalidations, שבמהלכו מבטלים שורות cache ישנות כדי לרוקן את ה-buffer ולאפשר המשך ביצוע. מצב זה עלול להתרחש גם לאחר הפעלת מחסום זיכרון, כאשר כל פעולות ה-store הבאות תלויות בהשלמת תהליך ה-invalidations, גם אם אין החמצת cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Line fill buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/line-fill-buffer/</guid>
      <description>&lt;p&gt;כשהנתונים שנכתבים לכתובת באזור זיכרון Write-Back ה-stores נמצאים ב-store buffer, הם נשארים שם עד שה-store מבצע פרישה. לאחר הפרישה, הנתונים נכתבים ל-L1 Data Cache אם השורה קיימת ויש לה הרשאת כתיבה. אם לא, ה-Line Fill Buffer (LFB) מוקצה לטיפול בכתיבה במקרה של store miss. ה-LFB מקבל בסופו של דבר את העותק העדכני של שורת ה-cache, כך שניתן להתקין אותה ב-L1 Data Cache ולבצע את הכתיבה של נתוני ה-store ל-cache. פרטים נוספים לגבי מיזוג, buffering, סדרי עדיפויות ו&amp;quot;קיצורי דרך&amp;quot; אינם תמיד ברורים, אך אחת מהפרשנויות היא ש-LFBs פועלים כ-buffers בגודל cache, שבהם מתמזגים נתוני ה-store לפני שליחתם ל-L1 Data Cache.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reorder buffer</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/reorder-buffer/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;ה-reorder buffer הוא יחידת חומרה המשמשת באופן נרחב יחד עם אלגוריתם Tomasulo לתמיכה בביצוע פקודות לא מסודרות וספקולטיביות. הוא מבטיח שההוראות יתבצעו בסדר המתואם.&lt;/p&gt;&#xA;&lt;p&gt;ה-buffer מיושם כמערך מעגלי, המיועד לספק תור לסדר הוראות שנמצאות בעיבוד לפי FIFO. הוא מאפשר רישום של תוצאות מול ההוראות כאשר הן מסתיימות, גם אם הן בוצעו מחוץ לסדר.&lt;/p&gt;&#xA;&lt;p&gt;מעבדי x86 מודרניים מבצעים loads ספקולטיביות מוקדמות לפני טעינות אחרות, ולעיתים עלולים &amp;ldquo;להשמיד&amp;rdquo; ספקולציה שגויה של סדר הזיכרון אם הם מזהים שהעותק שלהם של שורת ה-cache לא נשאר תקף מאז שה-load התבצעה בפועל, בהתאם להתרות הארכיטקטוניות. במקרה כזה, הם משליכים את תוכן ה-reorder buffer כדי לחזור למצב עקבי ולהתחיל מחדש את הביצוע. זה קורה בדרך כלל כאשר ליבה אחרת משנה את שורת ה-cache, אך עשוי להתרחש גם אם load חזה בטעות שלא תדרוש טעינה מחדש של store. (כמובן, מעבדי x86 אמיתיים יכולים לסדר מחדש בחופשיות טעינות לפני stores.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Uops</title>
      <link>https://smichaelshal.github.io/he/posts/processor-components/uops/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://smichaelshal.github.io/he/posts/processor-components/uops/</guid>
      <description>&lt;h2 id=&#34;מבוא&#34;&gt;מבוא&lt;/h2&gt;&#xA;&lt;p&gt;במעבדים, micro-operations (המכונות גם micro-ops או μops, ובאופן היסטורי micro-actions) הן הוראות ברמה נמוכה המשמשות ליישום הוראות מכונה מורכבות בעיצובים מסוימים (לעיתים מכונות פקודות מאקרו בהקשר זה).&lt;/p&gt;&#xA;&lt;p&gt;בדרך כלל, micro-operations מבצעות פעולות בסיסיות על נתונים המאוחסנים ברגיסטר אחד או יותר, כמו העברת נתונים בין רגיסטרים או בין רגיסטרים לבין bus-ים חיצוניים של המעבד (CPU), וכן ביצוע פעולות אריתמטיות או לוגיות על הנתונים ברגיסטרים. במחזור fetch -&amp;gt; decode -&amp;gt; execute טיפוסי, כל שלב בהוראת מאקרו מתפרק במהלך הביצוע, כך שהמעבד קובע ומבצע סדרה של micro-operations. הביצוע של micro-operations מתבצע תחת שליטת יחידת הבקרה של המעבד, אשר מבצעת אופטימיזציות שונות כמו סידור מחדש, היתוך ואחסון ב-cache.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
